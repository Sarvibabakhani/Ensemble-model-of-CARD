{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "psjvmpQl-TPw"
   },
   "source": [
    "#**CovidNet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0-3YNu6UVv64"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import  accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from dataloader import *\n",
    "from covidnet import covidnet\n",
    "from train import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JUGwCVQOGHk"
   },
   "source": [
    "we prepared a sharelink from google dive:\n",
    "\n",
    "https://drive.google.com/drive/folders/1aw7nqrXkBRZp94Ef04s3xeH-2gQRPb97?usp=sharing\n",
    "\n",
    "Add a shortcut to your own google drive and mount drive on google colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qU5WVpKKEL-J",
    "outputId": "15b20e9e-6533-4663-cd3f-294a3ab51f01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfo4MCK_A0Rf"
   },
   "source": [
    "##load data & model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ZaiW-JzWTqd",
    "outputId": "02c43a47-87a6-4e97-8e58-2c4c395980a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2928 validated image filenames belonging to 3 classes.\n",
      "Found 732 validated image filenames belonging to 3 classes.\n",
      "Found 915 validated image filenames belonging to 3 classes.\n",
      "Found 50 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "#DIRECTORIES\n",
    "path_metadata = \"/content/drive/MyDrive/dataset/metadata.csv\" ## directory of dataframe of image directories and classes\n",
    "path_pneumonia = \"/content/drive/MyDrive/dataset/Dataset/pneumonia\" ## directory of images of pneumonia classes\n",
    "directory_dataset='/content/drive/MyDrive/dataset/Dataset' ## directory of all classes folders\n",
    "\n",
    "image_size=(224, 224)\n",
    "batch_size = 32\n",
    "\n",
    "## call a function to load datasets\n",
    "train_dataset,validation_dataset,test_dataset, y_true,y_true_oh,train_steps,validation_steps,test_steps,_,_,_ = data_func(\n",
    "    batch_size ,\n",
    "    path_metadata ,\n",
    "    path_pneumonia ,\n",
    "    directory_dataset,\n",
    "    image_size )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8atWy0z1WXRZ"
   },
   "outputs": [],
   "source": [
    "input_shape = 224, 224, 3 # size and channel of images\n",
    "n_classes = 3 # number of classes\n",
    "\n",
    "# call the model\n",
    "model = covidnet(input_shape,n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1NJs2CcqAx9m"
   },
   "source": [
    "##train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "haKZOs1QWchH",
    "outputId": "7f77269a-a119-4146-f8bd-5b19bf0c1a55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "91/91 [==============================] - 1680s 18s/step - loss: 0.9495 - accuracy: 0.5124 - val_loss: 0.7252 - val_accuracy: 0.6577 - lr: 2.0000e-04\n",
      "Epoch 2/150\n",
      "91/91 [==============================] - 83s 908ms/step - loss: 0.7874 - accuracy: 0.6564 - val_loss: 0.6514 - val_accuracy: 0.7656 - lr: 2.0000e-04\n",
      "Epoch 3/150\n",
      "91/91 [==============================] - 82s 906ms/step - loss: 0.6956 - accuracy: 0.7048 - val_loss: 0.5879 - val_accuracy: 0.7884 - lr: 2.0000e-04\n",
      "Epoch 4/150\n",
      "91/91 [==============================] - 82s 903ms/step - loss: 0.6222 - accuracy: 0.7459 - val_loss: 0.5188 - val_accuracy: 0.8097 - lr: 2.0000e-04\n",
      "Epoch 5/150\n",
      "91/91 [==============================] - 81s 894ms/step - loss: 0.5827 - accuracy: 0.7655 - val_loss: 0.6119 - val_accuracy: 0.7216 - lr: 2.0000e-04\n",
      "Epoch 6/150\n",
      "91/91 [==============================] - 81s 887ms/step - loss: 0.5714 - accuracy: 0.7728 - val_loss: 0.6467 - val_accuracy: 0.7145 - lr: 2.0000e-04\n",
      "Epoch 7/150\n",
      "91/91 [==============================] - 80s 883ms/step - loss: 0.5274 - accuracy: 0.8042 - val_loss: 0.5663 - val_accuracy: 0.7841 - lr: 2.0000e-04\n",
      "Epoch 8/150\n",
      "91/91 [==============================] - 80s 881ms/step - loss: 0.5063 - accuracy: 0.8025 - val_loss: 0.5282 - val_accuracy: 0.7827 - lr: 2.0000e-04\n",
      "Epoch 9/150\n",
      "91/91 [==============================] - 81s 890ms/step - loss: 0.5096 - accuracy: 0.8049 - val_loss: 0.4558 - val_accuracy: 0.8324 - lr: 2.0000e-04\n",
      "Epoch 10/150\n",
      "91/91 [==============================] - 81s 894ms/step - loss: 0.4904 - accuracy: 0.8146 - val_loss: 0.4521 - val_accuracy: 0.8509 - lr: 2.0000e-04\n",
      "Epoch 11/150\n",
      "91/91 [==============================] - 81s 890ms/step - loss: 0.4835 - accuracy: 0.8201 - val_loss: 0.6949 - val_accuracy: 0.6989 - lr: 2.0000e-04\n",
      "Epoch 12/150\n",
      "91/91 [==============================] - 80s 883ms/step - loss: 0.4443 - accuracy: 0.8305 - val_loss: 0.6033 - val_accuracy: 0.7486 - lr: 2.0000e-04\n",
      "Epoch 13/150\n",
      "91/91 [==============================] - 81s 887ms/step - loss: 0.4457 - accuracy: 0.8239 - val_loss: 0.4474 - val_accuracy: 0.8452 - lr: 2.0000e-04\n",
      "Epoch 14/150\n",
      "91/91 [==============================] - 81s 886ms/step - loss: 0.4651 - accuracy: 0.8208 - val_loss: 0.4428 - val_accuracy: 0.8423 - lr: 2.0000e-04\n",
      "Epoch 15/150\n",
      "91/91 [==============================] - 80s 882ms/step - loss: 0.4399 - accuracy: 0.8301 - val_loss: 0.5977 - val_accuracy: 0.7557 - lr: 2.0000e-04\n",
      "Epoch 16/150\n",
      "91/91 [==============================] - 81s 893ms/step - loss: 0.4230 - accuracy: 0.8446 - val_loss: 0.3500 - val_accuracy: 0.8849 - lr: 1.8000e-04\n",
      "Epoch 17/150\n",
      "91/91 [==============================] - 80s 874ms/step - loss: 0.4044 - accuracy: 0.8522 - val_loss: 0.3709 - val_accuracy: 0.8793 - lr: 1.8000e-04\n",
      "Epoch 18/150\n",
      "91/91 [==============================] - 80s 878ms/step - loss: 0.3723 - accuracy: 0.8591 - val_loss: 0.3557 - val_accuracy: 0.8807 - lr: 1.8000e-04\n",
      "Epoch 19/150\n",
      "91/91 [==============================] - 80s 880ms/step - loss: 0.3886 - accuracy: 0.8564 - val_loss: 0.3825 - val_accuracy: 0.8665 - lr: 1.8000e-04\n",
      "Epoch 20/150\n",
      "91/91 [==============================] - 80s 877ms/step - loss: 0.3935 - accuracy: 0.8491 - val_loss: 0.5753 - val_accuracy: 0.7670 - lr: 1.8000e-04\n",
      "Epoch 21/150\n",
      "91/91 [==============================] - 80s 877ms/step - loss: 0.3652 - accuracy: 0.8695 - val_loss: 0.5647 - val_accuracy: 0.7699 - lr: 1.8000e-04\n",
      "Epoch 22/150\n",
      "91/91 [==============================] - 80s 876ms/step - loss: 0.3573 - accuracy: 0.8681 - val_loss: 0.3689 - val_accuracy: 0.8707 - lr: 1.6200e-04\n",
      "Epoch 23/150\n",
      "91/91 [==============================] - 79s 865ms/step - loss: 0.3514 - accuracy: 0.8760 - val_loss: 0.3563 - val_accuracy: 0.8807 - lr: 1.6200e-04\n",
      "Epoch 24/150\n",
      "91/91 [==============================] - 80s 880ms/step - loss: 0.3802 - accuracy: 0.8633 - val_loss: 0.3995 - val_accuracy: 0.8509 - lr: 1.6200e-04\n",
      "Epoch 25/150\n",
      "91/91 [==============================] - 80s 880ms/step - loss: 0.3603 - accuracy: 0.8674 - val_loss: 0.7273 - val_accuracy: 0.7244 - lr: 1.6200e-04\n",
      "Epoch 26/150\n",
      "91/91 [==============================] - 80s 882ms/step - loss: 0.3677 - accuracy: 0.8602 - val_loss: 0.4488 - val_accuracy: 0.8281 - lr: 1.6200e-04\n",
      "Epoch 27/150\n",
      "91/91 [==============================] - 80s 878ms/step - loss: 0.3378 - accuracy: 0.8771 - val_loss: 0.4560 - val_accuracy: 0.8381 - lr: 1.4580e-04\n",
      "Epoch 28/150\n",
      "91/91 [==============================] - 81s 888ms/step - loss: 0.3539 - accuracy: 0.8709 - val_loss: 0.6655 - val_accuracy: 0.7500 - lr: 1.4580e-04\n",
      "Epoch 29/150\n",
      "91/91 [==============================] - 80s 879ms/step - loss: 0.3384 - accuracy: 0.8760 - val_loss: 0.3843 - val_accuracy: 0.8523 - lr: 1.4580e-04\n",
      "Epoch 30/150\n",
      "91/91 [==============================] - 79s 869ms/step - loss: 0.3409 - accuracy: 0.8740 - val_loss: 0.3878 - val_accuracy: 0.8523 - lr: 1.4580e-04\n",
      "Epoch 31/150\n",
      "91/91 [==============================] - 80s 881ms/step - loss: 0.3176 - accuracy: 0.8860 - val_loss: 0.3542 - val_accuracy: 0.8750 - lr: 1.4580e-04\n",
      "Epoch 32/150\n",
      "91/91 [==============================] - 80s 879ms/step - loss: 0.3233 - accuracy: 0.8823 - val_loss: 0.4253 - val_accuracy: 0.8395 - lr: 1.3122e-04\n",
      "Epoch 33/150\n",
      "91/91 [==============================] - 80s 882ms/step - loss: 0.3080 - accuracy: 0.8933 - val_loss: 0.3099 - val_accuracy: 0.8977 - lr: 1.3122e-04\n",
      "Epoch 34/150\n",
      "91/91 [==============================] - 80s 882ms/step - loss: 0.3118 - accuracy: 0.8871 - val_loss: 0.3058 - val_accuracy: 0.8920 - lr: 1.3122e-04\n",
      "Epoch 35/150\n",
      "91/91 [==============================] - 79s 872ms/step - loss: 0.2945 - accuracy: 0.8940 - val_loss: 0.3383 - val_accuracy: 0.8821 - lr: 1.3122e-04\n",
      "Epoch 36/150\n",
      "91/91 [==============================] - 80s 876ms/step - loss: 0.2910 - accuracy: 0.8957 - val_loss: 0.3441 - val_accuracy: 0.8835 - lr: 1.3122e-04\n",
      "Epoch 37/150\n",
      "91/91 [==============================] - 80s 879ms/step - loss: 0.3078 - accuracy: 0.8954 - val_loss: 0.4476 - val_accuracy: 0.8267 - lr: 1.3122e-04\n",
      "Epoch 38/150\n",
      "91/91 [==============================] - 80s 875ms/step - loss: 0.3062 - accuracy: 0.8947 - val_loss: 0.4310 - val_accuracy: 0.8324 - lr: 1.3122e-04\n",
      "Epoch 39/150\n",
      "91/91 [==============================] - 80s 878ms/step - loss: 0.2912 - accuracy: 0.8947 - val_loss: 0.4201 - val_accuracy: 0.8494 - lr: 1.1810e-04\n",
      "Epoch 40/150\n",
      "91/91 [==============================] - 80s 877ms/step - loss: 0.2919 - accuracy: 0.8992 - val_loss: 0.3832 - val_accuracy: 0.8693 - lr: 1.1810e-04\n",
      "Epoch 41/150\n",
      "91/91 [==============================] - 79s 873ms/step - loss: 0.2957 - accuracy: 0.8954 - val_loss: 0.4951 - val_accuracy: 0.8125 - lr: 1.1810e-04\n",
      "Epoch 42/150\n",
      "91/91 [==============================] - 80s 877ms/step - loss: 0.2903 - accuracy: 0.8971 - val_loss: 0.3228 - val_accuracy: 0.8892 - lr: 1.1810e-04\n",
      "Epoch 43/150\n",
      "91/91 [==============================] - 80s 880ms/step - loss: 0.2845 - accuracy: 0.8988 - val_loss: 0.2778 - val_accuracy: 0.9148 - lr: 1.1810e-04\n",
      "Epoch 44/150\n",
      "91/91 [==============================] - 80s 876ms/step - loss: 0.2933 - accuracy: 0.8957 - val_loss: 0.4034 - val_accuracy: 0.8409 - lr: 1.1810e-04\n",
      "Epoch 45/150\n",
      "91/91 [==============================] - 80s 878ms/step - loss: 0.2630 - accuracy: 0.9078 - val_loss: 0.3905 - val_accuracy: 0.8523 - lr: 1.1810e-04\n",
      "Epoch 46/150\n",
      "91/91 [==============================] - 79s 869ms/step - loss: 0.2627 - accuracy: 0.9088 - val_loss: 0.3080 - val_accuracy: 0.8963 - lr: 1.1810e-04\n",
      "Epoch 47/150\n",
      "91/91 [==============================] - 80s 875ms/step - loss: 0.2783 - accuracy: 0.9054 - val_loss: 0.2983 - val_accuracy: 0.9006 - lr: 1.1810e-04\n",
      "Epoch 48/150\n",
      "91/91 [==============================] - 80s 877ms/step - loss: 0.2660 - accuracy: 0.9109 - val_loss: 0.3165 - val_accuracy: 0.8807 - lr: 1.1810e-04\n",
      "Epoch 49/150\n",
      "91/91 [==============================] - 79s 868ms/step - loss: 0.2698 - accuracy: 0.9078 - val_loss: 0.3824 - val_accuracy: 0.8480 - lr: 1.0629e-04\n",
      "Epoch 50/150\n",
      "91/91 [==============================] - 79s 866ms/step - loss: 0.2611 - accuracy: 0.9116 - val_loss: 0.3223 - val_accuracy: 0.8835 - lr: 1.0629e-04\n",
      "Epoch 51/150\n",
      "91/91 [==============================] - 80s 879ms/step - loss: 0.2652 - accuracy: 0.9085 - val_loss: 0.3141 - val_accuracy: 0.8849 - lr: 1.0629e-04\n",
      "Epoch 52/150\n",
      "91/91 [==============================] - 80s 874ms/step - loss: 0.2496 - accuracy: 0.9144 - val_loss: 0.2975 - val_accuracy: 0.8949 - lr: 1.0629e-04\n",
      "Epoch 53/150\n",
      "91/91 [==============================] - 80s 874ms/step - loss: 0.2706 - accuracy: 0.9099 - val_loss: 0.2665 - val_accuracy: 0.9119 - lr: 1.0629e-04\n",
      "Epoch 54/150\n",
      "91/91 [==============================] - 79s 872ms/step - loss: 0.2502 - accuracy: 0.9123 - val_loss: 0.3228 - val_accuracy: 0.8849 - lr: 9.5659e-05\n",
      "Epoch 55/150\n",
      "91/91 [==============================] - 79s 872ms/step - loss: 0.2554 - accuracy: 0.9137 - val_loss: 0.3043 - val_accuracy: 0.8935 - lr: 9.5659e-05\n",
      "Epoch 56/150\n",
      "91/91 [==============================] - 79s 872ms/step - loss: 0.2612 - accuracy: 0.9081 - val_loss: 0.3613 - val_accuracy: 0.8707 - lr: 9.5659e-05\n",
      "Epoch 57/150\n",
      "91/91 [==============================] - 80s 875ms/step - loss: 0.2372 - accuracy: 0.9189 - val_loss: 0.3144 - val_accuracy: 0.8835 - lr: 9.5659e-05\n",
      "Epoch 58/150\n",
      "91/91 [==============================] - 79s 866ms/step - loss: 0.2396 - accuracy: 0.9220 - val_loss: 0.2749 - val_accuracy: 0.9077 - lr: 9.5659e-05\n",
      "Epoch 59/150\n",
      "91/91 [==============================] - 79s 872ms/step - loss: 0.2428 - accuracy: 0.9141 - val_loss: 0.3244 - val_accuracy: 0.8821 - lr: 8.6093e-05\n",
      "Epoch 60/150\n",
      "91/91 [==============================] - 80s 874ms/step - loss: 0.2459 - accuracy: 0.9144 - val_loss: 0.3317 - val_accuracy: 0.8736 - lr: 8.6093e-05\n",
      "Epoch 61/150\n",
      "91/91 [==============================] - 79s 870ms/step - loss: 0.2316 - accuracy: 0.9199 - val_loss: 0.2953 - val_accuracy: 0.8991 - lr: 8.6093e-05\n",
      "Epoch 62/150\n",
      "91/91 [==============================] - 79s 870ms/step - loss: 0.2283 - accuracy: 0.9233 - val_loss: 0.3292 - val_accuracy: 0.8849 - lr: 8.6093e-05\n",
      "Epoch 63/150\n",
      "91/91 [==============================] - 80s 874ms/step - loss: 0.2441 - accuracy: 0.9133 - val_loss: 0.2646 - val_accuracy: 0.9048 - lr: 8.6093e-05\n",
      "Epoch 64/150\n",
      "91/91 [==============================] - 79s 871ms/step - loss: 0.2337 - accuracy: 0.9230 - val_loss: 0.3712 - val_accuracy: 0.8778 - lr: 7.7484e-05\n",
      "Epoch 65/150\n",
      "91/91 [==============================] - 79s 869ms/step - loss: 0.2261 - accuracy: 0.9227 - val_loss: 0.3760 - val_accuracy: 0.8693 - lr: 7.7484e-05\n",
      "Epoch 66/150\n",
      "91/91 [==============================] - 79s 872ms/step - loss: 0.2325 - accuracy: 0.9251 - val_loss: 0.2758 - val_accuracy: 0.9048 - lr: 7.7484e-05\n",
      "Epoch 67/150\n",
      "91/91 [==============================] - 79s 869ms/step - loss: 0.2271 - accuracy: 0.9240 - val_loss: 0.3284 - val_accuracy: 0.8963 - lr: 7.7484e-05\n",
      "Epoch 68/150\n",
      "91/91 [==============================] - 80s 874ms/step - loss: 0.2295 - accuracy: 0.9223 - val_loss: 0.2652 - val_accuracy: 0.8991 - lr: 7.7484e-05\n",
      "Epoch 69/150\n",
      "91/91 [==============================] - 79s 869ms/step - loss: 0.2329 - accuracy: 0.9220 - val_loss: 0.2936 - val_accuracy: 0.8991 - lr: 6.9736e-05\n",
      "Epoch 70/150\n",
      "91/91 [==============================] - 79s 868ms/step - loss: 0.2275 - accuracy: 0.9285 - val_loss: 0.2987 - val_accuracy: 0.9020 - lr: 6.9736e-05\n",
      "Epoch 71/150\n",
      "91/91 [==============================] - 80s 872ms/step - loss: 0.2243 - accuracy: 0.9240 - val_loss: 0.2917 - val_accuracy: 0.9006 - lr: 6.9736e-05\n",
      "Epoch 72/150\n",
      "91/91 [==============================] - 79s 864ms/step - loss: 0.2250 - accuracy: 0.9261 - val_loss: 0.3799 - val_accuracy: 0.8636 - lr: 6.9736e-05\n",
      "Epoch 73/150\n",
      "91/91 [==============================] - 79s 866ms/step - loss: 0.2100 - accuracy: 0.9296 - val_loss: 0.4045 - val_accuracy: 0.8665 - lr: 6.9736e-05\n",
      "Epoch 74/150\n",
      "91/91 [==============================] - 79s 874ms/step - loss: 0.2292 - accuracy: 0.9247 - val_loss: 0.3073 - val_accuracy: 0.8949 - lr: 6.2762e-05\n",
      "Epoch 75/150\n",
      "91/91 [==============================] - 79s 868ms/step - loss: 0.2121 - accuracy: 0.9254 - val_loss: 0.3409 - val_accuracy: 0.8807 - lr: 6.2762e-05\n",
      "Epoch 76/150\n",
      "91/91 [==============================] - 79s 872ms/step - loss: 0.2125 - accuracy: 0.9261 - val_loss: 0.4392 - val_accuracy: 0.8466 - lr: 6.2762e-05\n",
      "Epoch 77/150\n",
      "91/91 [==============================] - 80s 874ms/step - loss: 0.2180 - accuracy: 0.9244 - val_loss: 0.2590 - val_accuracy: 0.9077 - lr: 6.2762e-05\n",
      "Epoch 78/150\n",
      "91/91 [==============================] - 79s 869ms/step - loss: 0.2111 - accuracy: 0.9313 - val_loss: 0.2446 - val_accuracy: 0.9091 - lr: 6.2762e-05\n",
      "Epoch 79/150\n",
      "91/91 [==============================] - 79s 870ms/step - loss: 0.2122 - accuracy: 0.9278 - val_loss: 0.2591 - val_accuracy: 0.9062 - lr: 5.6486e-05\n",
      "Epoch 80/150\n",
      "91/91 [==============================] - 79s 867ms/step - loss: 0.2057 - accuracy: 0.9344 - val_loss: 0.2662 - val_accuracy: 0.9020 - lr: 5.6486e-05\n",
      "Epoch 81/150\n",
      "91/91 [==============================] - 79s 868ms/step - loss: 0.2076 - accuracy: 0.9306 - val_loss: 0.2981 - val_accuracy: 0.9006 - lr: 5.6486e-05\n",
      "Epoch 82/150\n",
      "91/91 [==============================] - 79s 867ms/step - loss: 0.1992 - accuracy: 0.9330 - val_loss: 0.3491 - val_accuracy: 0.8793 - lr: 5.6486e-05\n",
      "Epoch 83/150\n",
      "91/91 [==============================] - 79s 864ms/step - loss: 0.2187 - accuracy: 0.9292 - val_loss: 0.3483 - val_accuracy: 0.8722 - lr: 5.6486e-05\n",
      "Epoch 84/150\n",
      "91/91 [==============================] - 80s 883ms/step - loss: 0.2104 - accuracy: 0.9275 - val_loss: 0.2394 - val_accuracy: 0.9162 - lr: 5.0837e-05\n",
      "Epoch 85/150\n",
      "91/91 [==============================] - 79s 865ms/step - loss: 0.2092 - accuracy: 0.9254 - val_loss: 0.2765 - val_accuracy: 0.8920 - lr: 5.0837e-05\n",
      "Epoch 86/150\n",
      "91/91 [==============================] - 79s 871ms/step - loss: 0.2065 - accuracy: 0.9323 - val_loss: 0.3334 - val_accuracy: 0.8793 - lr: 5.0837e-05\n",
      "Epoch 87/150\n",
      "91/91 [==============================] - 79s 874ms/step - loss: 0.2003 - accuracy: 0.9306 - val_loss: 0.3199 - val_accuracy: 0.8878 - lr: 5.0837e-05\n",
      "Epoch 88/150\n",
      "91/91 [==============================] - 79s 863ms/step - loss: 0.1941 - accuracy: 0.9368 - val_loss: 0.3338 - val_accuracy: 0.8807 - lr: 5.0837e-05\n",
      "Epoch 89/150\n",
      "91/91 [==============================] - 79s 868ms/step - loss: 0.1950 - accuracy: 0.9334 - val_loss: 0.2554 - val_accuracy: 0.9162 - lr: 5.0837e-05\n",
      "Epoch 90/150\n",
      "91/91 [==============================] - 80s 874ms/step - loss: 0.2156 - accuracy: 0.9265 - val_loss: 0.3125 - val_accuracy: 0.8864 - lr: 4.5754e-05\n",
      "Epoch 91/150\n",
      "91/91 [==============================] - 79s 866ms/step - loss: 0.2059 - accuracy: 0.9323 - val_loss: 0.3094 - val_accuracy: 0.8807 - lr: 4.5754e-05\n",
      "Epoch 92/150\n",
      "91/91 [==============================] - 79s 865ms/step - loss: 0.1979 - accuracy: 0.9323 - val_loss: 0.3836 - val_accuracy: 0.8679 - lr: 4.5754e-05\n",
      "Epoch 93/150\n",
      "91/91 [==============================] - 79s 868ms/step - loss: 0.2011 - accuracy: 0.9330 - val_loss: 0.3687 - val_accuracy: 0.8693 - lr: 4.5754e-05\n",
      "Epoch 94/150\n",
      "91/91 [==============================] - 80s 884ms/step - loss: 0.1995 - accuracy: 0.9320 - val_loss: 0.2987 - val_accuracy: 0.8864 - lr: 4.5754e-05\n",
      "Epoch 95/150\n",
      "91/91 [==============================] - 79s 870ms/step - loss: 0.1916 - accuracy: 0.9347 - val_loss: 0.2162 - val_accuracy: 0.9134 - lr: 4.1178e-05\n",
      "Epoch 96/150\n",
      "91/91 [==============================] - 80s 876ms/step - loss: 0.1914 - accuracy: 0.9358 - val_loss: 0.2265 - val_accuracy: 0.9190 - lr: 4.1178e-05\n",
      "Epoch 97/150\n",
      "91/91 [==============================] - 79s 867ms/step - loss: 0.1922 - accuracy: 0.9358 - val_loss: 0.3120 - val_accuracy: 0.8864 - lr: 4.1178e-05\n",
      "Epoch 98/150\n",
      "91/91 [==============================] - 80s 881ms/step - loss: 0.1858 - accuracy: 0.9365 - val_loss: 0.2656 - val_accuracy: 0.9062 - lr: 4.1178e-05\n",
      "Epoch 99/150\n",
      "91/91 [==============================] - 80s 881ms/step - loss: 0.1889 - accuracy: 0.9354 - val_loss: 0.2469 - val_accuracy: 0.9077 - lr: 4.1178e-05\n",
      "Epoch 100/150\n",
      "91/91 [==============================] - 80s 873ms/step - loss: 0.1939 - accuracy: 0.9354 - val_loss: 0.2544 - val_accuracy: 0.9091 - lr: 4.1178e-05\n",
      "Epoch 101/150\n",
      "91/91 [==============================] - 79s 872ms/step - loss: 0.2027 - accuracy: 0.9344 - val_loss: 0.3108 - val_accuracy: 0.8935 - lr: 4.1178e-05\n",
      "Epoch 102/150\n",
      "91/91 [==============================] - 79s 872ms/step - loss: 0.1925 - accuracy: 0.9310 - val_loss: 0.2957 - val_accuracy: 0.8892 - lr: 3.7060e-05\n",
      "Epoch 103/150\n",
      "91/91 [==============================] - 80s 877ms/step - loss: 0.1964 - accuracy: 0.9299 - val_loss: 0.3134 - val_accuracy: 0.8878 - lr: 3.7060e-05\n",
      "Epoch 104/150\n",
      "91/91 [==============================] - 80s 876ms/step - loss: 0.1814 - accuracy: 0.9403 - val_loss: 0.2609 - val_accuracy: 0.9020 - lr: 3.7060e-05\n",
      "Epoch 105/150\n",
      "91/91 [==============================] - 79s 869ms/step - loss: 0.1875 - accuracy: 0.9340 - val_loss: 0.2931 - val_accuracy: 0.8878 - lr: 3.7060e-05\n",
      "Epoch 106/150\n",
      "91/91 [==============================] - 79s 870ms/step - loss: 0.1993 - accuracy: 0.9320 - val_loss: 0.2362 - val_accuracy: 0.9134 - lr: 3.7060e-05\n",
      "Epoch 107/150\n",
      "91/91 [==============================] - 80s 874ms/step - loss: 0.1823 - accuracy: 0.9378 - val_loss: 0.2323 - val_accuracy: 0.9205 - lr: 3.3354e-05\n",
      "Epoch 108/150\n",
      "91/91 [==============================] - 79s 868ms/step - loss: 0.1841 - accuracy: 0.9378 - val_loss: 0.3243 - val_accuracy: 0.8849 - lr: 3.3354e-05\n",
      "Epoch 109/150\n",
      "91/91 [==============================] - 79s 867ms/step - loss: 0.1942 - accuracy: 0.9334 - val_loss: 0.3695 - val_accuracy: 0.8665 - lr: 3.3354e-05\n",
      "Epoch 110/150\n",
      "91/91 [==============================] - 79s 873ms/step - loss: 0.1933 - accuracy: 0.9302 - val_loss: 0.2471 - val_accuracy: 0.9062 - lr: 3.3354e-05\n",
      "Epoch 111/150\n",
      "91/91 [==============================] - 79s 870ms/step - loss: 0.1858 - accuracy: 0.9385 - val_loss: 0.2659 - val_accuracy: 0.9020 - lr: 3.3354e-05\n",
      "Epoch 112/150\n",
      "91/91 [==============================] - 78s 861ms/step - loss: 0.1834 - accuracy: 0.9347 - val_loss: 0.3630 - val_accuracy: 0.8679 - lr: 3.3354e-05\n",
      "Epoch 113/150\n",
      "91/91 [==============================] - 79s 872ms/step - loss: 0.1822 - accuracy: 0.9392 - val_loss: 0.2284 - val_accuracy: 0.9176 - lr: 3.0019e-05\n",
      "Epoch 114/150\n",
      "91/91 [==============================] - 79s 867ms/step - loss: 0.1865 - accuracy: 0.9372 - val_loss: 0.3669 - val_accuracy: 0.8722 - lr: 3.0019e-05\n",
      "Epoch 115/150\n",
      "91/91 [==============================] - 80s 877ms/step - loss: 0.1814 - accuracy: 0.9385 - val_loss: 0.2543 - val_accuracy: 0.9062 - lr: 3.0019e-05\n",
      "Epoch 116/150\n",
      "91/91 [==============================] - 79s 869ms/step - loss: 0.1812 - accuracy: 0.9413 - val_loss: 0.2740 - val_accuracy: 0.9006 - lr: 3.0019e-05\n",
      "Epoch 117/150\n",
      "91/91 [==============================] - 79s 872ms/step - loss: 0.1831 - accuracy: 0.9372 - val_loss: 0.2978 - val_accuracy: 0.9006 - lr: 3.0019e-05\n",
      "Epoch 118/150\n",
      "91/91 [==============================] - 82s 894ms/step - loss: 0.1807 - accuracy: 0.9420 - val_loss: 0.2791 - val_accuracy: 0.9048 - lr: 2.7017e-05\n",
      "Epoch 119/150\n",
      "91/91 [==============================] - 79s 869ms/step - loss: 0.1781 - accuracy: 0.9403 - val_loss: 0.2628 - val_accuracy: 0.9048 - lr: 2.7017e-05\n",
      "Epoch 120/150\n",
      "91/91 [==============================] - 79s 870ms/step - loss: 0.1739 - accuracy: 0.9416 - val_loss: 0.2356 - val_accuracy: 0.9119 - lr: 2.7017e-05\n",
      "Epoch 121/150\n",
      "91/91 [==============================] - 80s 871ms/step - loss: 0.1706 - accuracy: 0.9413 - val_loss: 0.2359 - val_accuracy: 0.9134 - lr: 2.7017e-05\n",
      "Epoch 122/150\n",
      "91/91 [==============================] - 79s 866ms/step - loss: 0.1796 - accuracy: 0.9396 - val_loss: 0.2412 - val_accuracy: 0.9119 - lr: 2.7017e-05\n",
      "Epoch 123/150\n",
      "91/91 [==============================] - 79s 870ms/step - loss: 0.1816 - accuracy: 0.9392 - val_loss: 0.3552 - val_accuracy: 0.8807 - lr: 2.4315e-05\n",
      "Epoch 124/150\n",
      "91/91 [==============================] - 79s 865ms/step - loss: 0.1775 - accuracy: 0.9375 - val_loss: 0.2485 - val_accuracy: 0.9062 - lr: 2.4315e-05\n",
      "Epoch 125/150\n",
      "91/91 [==============================] - 79s 869ms/step - loss: 0.1830 - accuracy: 0.9337 - val_loss: 0.2653 - val_accuracy: 0.9006 - lr: 2.4315e-05\n",
      "Epoch 126/150\n",
      "91/91 [==============================] - 79s 870ms/step - loss: 0.1703 - accuracy: 0.9444 - val_loss: 0.2540 - val_accuracy: 0.9034 - lr: 2.4315e-05\n",
      "Epoch 127/150\n",
      "91/91 [==============================] - 79s 870ms/step - loss: 0.1760 - accuracy: 0.9406 - val_loss: 0.2926 - val_accuracy: 0.8949 - lr: 2.4315e-05\n",
      "Epoch 128/150\n",
      "91/91 [==============================] - 79s 869ms/step - loss: 0.1777 - accuracy: 0.9410 - val_loss: 0.3399 - val_accuracy: 0.8693 - lr: 2.1884e-05\n",
      "Epoch 129/150\n",
      "91/91 [==============================] - 79s 867ms/step - loss: 0.1657 - accuracy: 0.9461 - val_loss: 0.3464 - val_accuracy: 0.8750 - lr: 2.1884e-05\n",
      "Epoch 130/150\n",
      "91/91 [==============================] - 80s 877ms/step - loss: 0.1760 - accuracy: 0.9396 - val_loss: 0.2669 - val_accuracy: 0.9034 - lr: 2.1884e-05\n",
      "Epoch 131/150\n",
      "91/91 [==============================] - 80s 882ms/step - loss: 0.1743 - accuracy: 0.9396 - val_loss: 0.2317 - val_accuracy: 0.9148 - lr: 2.1884e-05\n",
      "Epoch 132/150\n",
      "91/91 [==============================] - 79s 866ms/step - loss: 0.1699 - accuracy: 0.9434 - val_loss: 0.3098 - val_accuracy: 0.8949 - lr: 2.1884e-05\n",
      "Epoch 133/150\n",
      "91/91 [==============================] - 79s 873ms/step - loss: 0.1713 - accuracy: 0.9420 - val_loss: 0.2204 - val_accuracy: 0.9205 - lr: 1.9695e-05\n",
      "Epoch 134/150\n",
      "91/91 [==============================] - 79s 865ms/step - loss: 0.1715 - accuracy: 0.9396 - val_loss: 0.2611 - val_accuracy: 0.9048 - lr: 1.9695e-05\n",
      "Epoch 135/150\n",
      "91/91 [==============================] - 80s 879ms/step - loss: 0.1697 - accuracy: 0.9399 - val_loss: 0.2217 - val_accuracy: 0.9233 - lr: 1.9695e-05\n",
      "Epoch 136/150\n",
      "91/91 [==============================] - 79s 873ms/step - loss: 0.1784 - accuracy: 0.9399 - val_loss: 0.2436 - val_accuracy: 0.9091 - lr: 1.9695e-05\n",
      "Epoch 137/150\n",
      "91/91 [==============================] - 79s 871ms/step - loss: 0.1716 - accuracy: 0.9403 - val_loss: 0.2696 - val_accuracy: 0.9020 - lr: 1.9695e-05\n",
      "Epoch 138/150\n",
      "91/91 [==============================] - 79s 866ms/step - loss: 0.1775 - accuracy: 0.9378 - val_loss: 0.2344 - val_accuracy: 0.9134 - lr: 1.9695e-05\n",
      "Epoch 139/150\n",
      "91/91 [==============================] - 79s 865ms/step - loss: 0.1696 - accuracy: 0.9461 - val_loss: 0.3620 - val_accuracy: 0.8849 - lr: 1.9695e-05\n",
      "Epoch 140/150\n",
      "91/91 [==============================] - 79s 869ms/step - loss: 0.1686 - accuracy: 0.9420 - val_loss: 0.2693 - val_accuracy: 0.8991 - lr: 1.9695e-05\n",
      "Epoch 141/150\n",
      "91/91 [==============================] - 79s 872ms/step - loss: 0.1746 - accuracy: 0.9416 - val_loss: 0.2721 - val_accuracy: 0.8977 - lr: 1.7726e-05\n",
      "Epoch 142/150\n",
      "91/91 [==============================] - 79s 869ms/step - loss: 0.1727 - accuracy: 0.9420 - val_loss: 0.3339 - val_accuracy: 0.8793 - lr: 1.7726e-05\n",
      "Epoch 143/150\n",
      "91/91 [==============================] - 79s 868ms/step - loss: 0.1740 - accuracy: 0.9410 - val_loss: 0.2368 - val_accuracy: 0.9119 - lr: 1.7726e-05\n",
      "Epoch 144/150\n",
      "91/91 [==============================] - 79s 873ms/step - loss: 0.1684 - accuracy: 0.9430 - val_loss: 0.2451 - val_accuracy: 0.9105 - lr: 1.7726e-05\n",
      "Epoch 145/150\n",
      "91/91 [==============================] - 79s 868ms/step - loss: 0.1660 - accuracy: 0.9437 - val_loss: 0.2426 - val_accuracy: 0.9091 - lr: 1.7726e-05\n",
      "Epoch 146/150\n",
      "91/91 [==============================] - 80s 875ms/step - loss: 0.1715 - accuracy: 0.9416 - val_loss: 0.3174 - val_accuracy: 0.8906 - lr: 1.5953e-05\n",
      "Epoch 147/150\n",
      "91/91 [==============================] - 79s 872ms/step - loss: 0.1672 - accuracy: 0.9413 - val_loss: 0.2884 - val_accuracy: 0.8977 - lr: 1.5953e-05\n",
      "Epoch 148/150\n",
      "91/91 [==============================] - 79s 864ms/step - loss: 0.1765 - accuracy: 0.9399 - val_loss: 0.2417 - val_accuracy: 0.9148 - lr: 1.5953e-05\n",
      "Epoch 149/150\n",
      "91/91 [==============================] - 79s 869ms/step - loss: 0.1699 - accuracy: 0.9410 - val_loss: 0.2591 - val_accuracy: 0.9091 - lr: 1.5953e-05\n",
      "Epoch 150/150\n",
      "91/91 [==============================] - 79s 872ms/step - loss: 0.1720 - accuracy: 0.9427 - val_loss: 0.3359 - val_accuracy: 0.8849 - lr: 1.5953e-05\n",
      "Total run time = 226.71 min\n"
     ]
    }
   ],
   "source": [
    "checkpoint_filepath =  '/content/covid'\n",
    "opt = Adam(learning_rate = 0.0002)\n",
    "\n",
    "from time import time\n",
    "start = time()\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "  history_covidnet,model2 = train(train_dataset, model,'covidnet',\n",
    "           train_steps,\n",
    "           validation_dataset,\n",
    "           validation_steps,\n",
    "           checkpoint_filepath,\n",
    "           epoch=150,\n",
    "           opt = opt)\n",
    "\n",
    "print('Total run time = {:.2f} min'.format((time()-start)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w67iXX3xAtBu"
   },
   "source": [
    "### model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o6WxGxInApQb",
    "outputId": "8d871431-1ef5-4ef4-dcb9-06310388ae42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 112, 112, 48  7104        ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 56, 56, 48)   0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 56, 56, 48)   2352        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 56, 56, 48)   2352        ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " depthwise_conv2d (DepthwiseCon  (None, 56, 56, 48)  480         ['conv2d_3[0][0]']               \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 56, 56, 48)   2352        ['depthwise_conv2d[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 56, 56, 48)   2352        ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 56, 56, 48)   2352        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 56, 56, 48)   0           ['conv2d_5[0][0]',               \n",
      "                                                                  'conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 56, 56, 48)   2352        ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 56, 56, 48)   2352        ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " depthwise_conv2d_1 (DepthwiseC  (None, 56, 56, 48)  480         ['conv2d_7[0][0]']               \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 56, 56, 48)   2352        ['depthwise_conv2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 56, 56, 48)   2352        ['conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 56, 56, 48)   0           ['conv2d_5[0][0]',               \n",
      "                                                                  'conv2d_9[0][0]',               \n",
      "                                                                  'conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 56, 56, 48)   2352        ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 56, 56, 48)   2352        ['conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " depthwise_conv2d_2 (DepthwiseC  (None, 56, 56, 48)  480         ['conv2d_11[0][0]']              \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 56, 56, 48)   2352        ['depthwise_conv2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 56, 56, 48)   2352        ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 56, 56, 48)   0           ['conv2d_5[0][0]',               \n",
      "                                                                  'conv2d_9[0][0]',               \n",
      "                                                                  'conv2d_13[0][0]',              \n",
      "                                                                  'conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 56, 56, 96)   4704        ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 56, 56, 96)   9312        ['conv2d_15[0][0]']              \n",
      "                                                                                                  \n",
      " depthwise_conv2d_3 (DepthwiseC  (None, 28, 28, 96)  960         ['conv2d_16[0][0]']              \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 56, 56, 48)   0           ['conv2d_5[0][0]',               \n",
      "                                                                  'conv2d_9[0][0]',               \n",
      "                                                                  'conv2d_13[0][0]',              \n",
      "                                                                  'conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 28, 28, 96)   9312        ['depthwise_conv2d_3[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 56, 56, 96)   4704        ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 28, 28, 96)   9312        ['conv2d_17[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 28, 28, 96)  0           ['conv2d_14[0][0]']              \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 28, 28, 96)   0           ['conv2d_18[0][0]',              \n",
      "                                                                  'max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 28, 28, 96)   9312        ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 28, 28, 96)   9312        ['conv2d_19[0][0]']              \n",
      "                                                                                                  \n",
      " depthwise_conv2d_4 (DepthwiseC  (None, 28, 28, 96)  960         ['conv2d_20[0][0]']              \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 28, 28, 96)   9312        ['depthwise_conv2d_4[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 28, 28, 96)   9312        ['conv2d_21[0][0]']              \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 28, 28, 96)   0           ['conv2d_18[0][0]',              \n",
      "                                                                  'conv2d_22[0][0]',              \n",
      "                                                                  'max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 28, 28, 96)   9312        ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 28, 28, 96)   9312        ['conv2d_23[0][0]']              \n",
      "                                                                                                  \n",
      " depthwise_conv2d_5 (DepthwiseC  (None, 28, 28, 96)  960         ['conv2d_24[0][0]']              \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 28, 28, 96)   9312        ['depthwise_conv2d_5[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 28, 28, 96)   9312        ['conv2d_25[0][0]']              \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 28, 28, 96)   0           ['conv2d_18[0][0]',              \n",
      "                                                                  'conv2d_22[0][0]',              \n",
      "                                                                  'conv2d_26[0][0]',              \n",
      "                                                                  'max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 28, 28, 96)   9312        ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 28, 28, 96)   9312        ['conv2d_27[0][0]']              \n",
      "                                                                                                  \n",
      " depthwise_conv2d_6 (DepthwiseC  (None, 28, 28, 96)  960         ['conv2d_28[0][0]']              \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 28, 28, 96)   9312        ['depthwise_conv2d_6[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 28, 28, 96)   9312        ['conv2d_29[0][0]']              \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 28, 28, 96)   0           ['conv2d_18[0][0]',              \n",
      "                                                                  'conv2d_22[0][0]',              \n",
      "                                                                  'conv2d_26[0][0]',              \n",
      "                                                                  'conv2d_30[0][0]',              \n",
      "                                                                  'max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 28, 28, 192)  18624       ['add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 28, 28, 192)  37056       ['conv2d_32[0][0]']              \n",
      "                                                                                                  \n",
      " depthwise_conv2d_7 (DepthwiseC  (None, 14, 14, 192)  1920       ['conv2d_33[0][0]']              \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 28, 28, 96)   0           ['conv2d_18[0][0]',              \n",
      "                                                                  'conv2d_22[0][0]',              \n",
      "                                                                  'conv2d_26[0][0]',              \n",
      "                                                                  'conv2d_30[0][0]',              \n",
      "                                                                  'max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 14, 14, 192)  37056       ['depthwise_conv2d_7[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 28, 28, 192)  18624       ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 14, 14, 192)  37056       ['conv2d_34[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 192)  0          ['conv2d_31[0][0]']              \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 14, 14, 192)  0           ['conv2d_35[0][0]',              \n",
      "                                                                  'max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 14, 14, 192)  37056       ['add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 14, 14, 192)  37056       ['conv2d_36[0][0]']              \n",
      "                                                                                                  \n",
      " depthwise_conv2d_8 (DepthwiseC  (None, 14, 14, 192)  1920       ['conv2d_37[0][0]']              \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 14, 14, 192)  37056       ['depthwise_conv2d_8[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 14, 14, 192)  37056       ['conv2d_38[0][0]']              \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 14, 14, 192)  0           ['conv2d_35[0][0]',              \n",
      "                                                                  'conv2d_39[0][0]',              \n",
      "                                                                  'max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 14, 14, 192)  37056       ['add_10[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 14, 14, 192)  37056       ['conv2d_40[0][0]']              \n",
      "                                                                                                  \n",
      " depthwise_conv2d_9 (DepthwiseC  (None, 14, 14, 192)  1920       ['conv2d_41[0][0]']              \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 14, 14, 192)  37056       ['depthwise_conv2d_9[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 14, 14, 192)  37056       ['conv2d_42[0][0]']              \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 14, 14, 192)  0           ['conv2d_35[0][0]',              \n",
      "                                                                  'conv2d_39[0][0]',              \n",
      "                                                                  'conv2d_43[0][0]',              \n",
      "                                                                  'max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 14, 14, 192)  37056       ['add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 14, 14, 192)  37056       ['conv2d_44[0][0]']              \n",
      "                                                                                                  \n",
      " depthwise_conv2d_10 (Depthwise  (None, 14, 14, 192)  1920       ['conv2d_45[0][0]']              \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 14, 14, 192)  37056       ['depthwise_conv2d_10[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 14, 14, 192)  37056       ['conv2d_46[0][0]']              \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 14, 14, 192)  0           ['conv2d_35[0][0]',              \n",
      "                                                                  'conv2d_39[0][0]',              \n",
      "                                                                  'conv2d_43[0][0]',              \n",
      "                                                                  'conv2d_47[0][0]',              \n",
      "                                                                  'max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 14, 14, 192)  37056       ['add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 14, 14, 192)  37056       ['conv2d_48[0][0]']              \n",
      "                                                                                                  \n",
      " depthwise_conv2d_11 (Depthwise  (None, 14, 14, 192)  1920       ['conv2d_49[0][0]']              \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 14, 14, 192)  37056       ['depthwise_conv2d_11[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 14, 14, 192)  37056       ['conv2d_50[0][0]']              \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 14, 14, 192)  0           ['conv2d_35[0][0]',              \n",
      "                                                                  'conv2d_39[0][0]',              \n",
      "                                                                  'conv2d_43[0][0]',              \n",
      "                                                                  'conv2d_47[0][0]',              \n",
      "                                                                  'conv2d_51[0][0]',              \n",
      "                                                                  'max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 14, 14, 192)  37056       ['add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 14, 14, 192)  37056       ['conv2d_52[0][0]']              \n",
      "                                                                                                  \n",
      " depthwise_conv2d_12 (Depthwise  (None, 14, 14, 192)  1920       ['conv2d_53[0][0]']              \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 14, 14, 192)  37056       ['depthwise_conv2d_12[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 14, 14, 192)  37056       ['conv2d_54[0][0]']              \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 14, 14, 192)  0           ['conv2d_35[0][0]',              \n",
      "                                                                  'conv2d_39[0][0]',              \n",
      "                                                                  'conv2d_43[0][0]',              \n",
      "                                                                  'conv2d_47[0][0]',              \n",
      "                                                                  'conv2d_51[0][0]',              \n",
      "                                                                  'conv2d_55[0][0]',              \n",
      "                                                                  'max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 14, 14, 384)  74112       ['add_15[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 14, 14, 384)  147840      ['conv2d_57[0][0]']              \n",
      "                                                                                                  \n",
      " depthwise_conv2d_13 (Depthwise  (None, 7, 7, 384)   3840        ['conv2d_58[0][0]']              \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 14, 14, 192)  0           ['conv2d_35[0][0]',              \n",
      "                                                                  'conv2d_39[0][0]',              \n",
      "                                                                  'conv2d_43[0][0]',              \n",
      "                                                                  'conv2d_47[0][0]',              \n",
      "                                                                  'conv2d_51[0][0]',              \n",
      "                                                                  'conv2d_55[0][0]',              \n",
      "                                                                  'max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)             (None, 7, 7, 384)    147840      ['depthwise_conv2d_13[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 14, 14, 384)  74112       ['add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)             (None, 7, 7, 384)    147840      ['conv2d_59[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 7, 7, 384)   0           ['conv2d_56[0][0]']              \n",
      "                                                                                                  \n",
      " add_16 (Add)                   (None, 7, 7, 384)    0           ['conv2d_60[0][0]',              \n",
      "                                                                  'max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 7, 7, 384)    147840      ['add_16[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 7, 7, 384)    147840      ['conv2d_61[0][0]']              \n",
      "                                                                                                  \n",
      " depthwise_conv2d_14 (Depthwise  (None, 7, 7, 384)   3840        ['conv2d_62[0][0]']              \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 7, 7, 384)    147840      ['depthwise_conv2d_14[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)             (None, 7, 7, 384)    147840      ['conv2d_63[0][0]']              \n",
      "                                                                                                  \n",
      " add_17 (Add)                   (None, 7, 7, 384)    0           ['conv2d_60[0][0]',              \n",
      "                                                                  'conv2d_64[0][0]',              \n",
      "                                                                  'max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)             (None, 7, 7, 384)    147840      ['add_17[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)             (None, 7, 7, 384)    147840      ['conv2d_65[0][0]']              \n",
      "                                                                                                  \n",
      " depthwise_conv2d_15 (Depthwise  (None, 7, 7, 384)   3840        ['conv2d_66[0][0]']              \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)             (None, 7, 7, 384)    147840      ['depthwise_conv2d_15[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)             (None, 7, 7, 384)    147840      ['conv2d_67[0][0]']              \n",
      "                                                                                                  \n",
      " add_18 (Add)                   (None, 7, 7, 384)    0           ['conv2d_60[0][0]',              \n",
      "                                                                  'conv2d_64[0][0]',              \n",
      "                                                                  'conv2d_68[0][0]',              \n",
      "                                                                  'max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 18816)        0           ['add_18[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 96)           1806432     ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 48)           4656        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 3)            147         ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,690,323\n",
      "Trainable params: 4,690,323\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ioFyOz9_c_Y"
   },
   "source": [
    "## test evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FwUwpSJhIEAz",
    "outputId": "ad8ea214-2e9b-4652-864b-93cbf2068b5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "915/915 [==============================] - 368s 402ms/step - loss: 0.2883 - accuracy: 0.8918\n",
      "Loss:  0.2883496582508087\n",
      "Accuracy:  0.8918032646179199\n"
     ]
    }
   ],
   "source": [
    "#evaluation with last epoch weights\n",
    "loss, accuracy = model2.evaluate(test_dataset)\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OKfABf7k-7hJ",
    "outputId": "19cb790c-edae-4a47-e793-092c797c5156"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f4efd522a40>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the weights with the best accuracy of validation dataset\n",
    "model2.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_EE9N6X9_ZQV",
    "outputId": "cb26fb3d-bd6c-43d0-99a6-70b5102f531d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "915/915 [==============================] - 15s 16ms/step - loss: 0.1932 - accuracy: 0.9410\n",
      "Loss:  0.1932021677494049\n",
      "Accuracy:  0.9409835934638977\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model2.evaluate(test_dataset)\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z2DEoxIC_l-p",
    "outputId": "d11be486-ad92-43f9-8125-0de7c44d1303"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "915/915 [==============================] - 15s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "  test_values = model2.predict(test_dataset, steps=test_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "znvwCsjT_ptD"
   },
   "outputs": [],
   "source": [
    "#save the prediction of the model on the test dataset to use in ensemble model\n",
    "np.save(\"test_p_covid\", test_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F7UEG33mAPeW"
   },
   "source": [
    "### precision, recall, fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ajWPdzno_qff"
   },
   "outputs": [],
   "source": [
    "# preparing test result\n",
    "\n",
    "test_value_max = np.argmax(test_values,axis=1)\n",
    "test_value_max_oh = convert_to_one_hot(test_value_max,3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aOmbjA1e_3mt",
    "outputId": "c1bb39a3-972a-4fbc-fc12-3e5f0c6ac607"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 94.10%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92       280\n",
      "           1       0.96      0.97      0.96       320\n",
      "           2       0.99      0.90      0.94       315\n",
      "\n",
      "   micro avg       0.94      0.94      0.94       915\n",
      "   macro avg       0.94      0.94      0.94       915\n",
      "weighted avg       0.94      0.94      0.94       915\n",
      " samples avg       0.94      0.94      0.94       915\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_true_oh, test_value_max_oh)\n",
    "\n",
    "print('Accuracy = {:.2f}%'.format(accuracy*100))\n",
    "print(classification_report(y_true_oh, test_value_max_oh,target_names=['0','1','2']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y9VnEw6W-k75"
   },
   "source": [
    "###confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "TMvVEbp2BE3P",
    "outputId": "24f4ecf7-7b43-45e5-d3a1-a6d51af74c5d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 700x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cf_matrix = confusion_matrix(y_true,test_value_max)\n",
    "\n",
    "plt.figure(figsize = (7,5))\n",
    "plt.title('Covidnet')\n",
    "x_axis_labels = ['Normal','Covid','Pneumonia']\n",
    "sns.heatmap(cf_matrix, annot=True,  fmt='g', cmap=\"Greens\", xticklabels=x_axis_labels, yticklabels=x_axis_labels)\n",
    "plt.xlabel('Prediction class', color = 'r')\n",
    "plt.ylabel(ylabel='True Class', color=\"r\")\n",
    "plt.savefig('h_covid.png')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "w67iXX3xAtBu"
   ],
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
