{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJbCkRmhKv01"
   },
   "source": [
    "#**Attention-Resnet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0-3YNu6UVv64"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from dataloader import *\n",
    "from atten_resnet import atten_resnet\n",
    "from train import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AzHShMcgOstQ"
   },
   "source": [
    "we prepared a sharelink from google dive:\n",
    "\n",
    "https://drive.google.com/drive/folders/1aw7nqrXkBRZp94Ef04s3xeH-2gQRPb97?usp=sharing\n",
    "\n",
    "Add a shortcut to your own google drive and mount drive on google colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4q4vZCfEEOtK",
    "outputId": "0336355e-ed37-4684-e117-614d3bd882e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfo4MCK_A0Rf"
   },
   "source": [
    "##load data & model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ZaiW-JzWTqd",
    "outputId": "a345c8da-d7a4-41ab-be5a-3846a85cbd7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2928 validated image filenames belonging to 3 classes.\n",
      "Found 732 validated image filenames belonging to 3 classes.\n",
      "Found 915 validated image filenames belonging to 3 classes.\n",
      "Found 50 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "#DIRECTORIES\n",
    "path_metadata = \"/content/drive/MyDrive/dataset/metadata.csv\" ## directory of dataframe of image directories and classes\n",
    "path_pneumonia = \"/content/drive/MyDrive/dataset/Dataset/pneumonia\" ## directory of images of pneumonia classes\n",
    "directory_dataset='/content/drive/MyDrive/dataset/Dataset' ## directory of all classes folders\n",
    "\n",
    "image_size=(224, 224)\n",
    "batch_size = 32\n",
    "\n",
    "## call a function to load datasets\n",
    "train_dataset,validation_dataset,test_dataset, y_true,y_true_oh,train_steps,validation_steps,test_steps,_,_,_ = data_func(\n",
    "    batch_size ,\n",
    "    path_metadata ,\n",
    "    path_pneumonia ,\n",
    "    directory_dataset,\n",
    "    image_size )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8atWy0z1WXRZ"
   },
   "outputs": [],
   "source": [
    "input_shape = 224, 224, 3 # size and channel of images\n",
    "n_classes = 3 # number of classes\n",
    "\n",
    "# call the model\n",
    "model = atten_resnet(input_shape,n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1NJs2CcqAx9m"
   },
   "source": [
    "##train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "haKZOs1QWchH",
    "outputId": "04798150-1771-466c-a214-6826ac6dad14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "91/91 [==============================] - 731s 7s/step - loss: 27.0942 - accuracy: 0.5325 - val_loss: 11.3238 - val_accuracy: 0.5298 - lr: 1.0000e-04\n",
      "Epoch 2/150\n",
      "91/91 [==============================] - 90s 986ms/step - loss: 12.0350 - accuracy: 0.6008 - val_loss: 10.2764 - val_accuracy: 0.6761 - lr: 1.0000e-04\n",
      "Epoch 3/150\n",
      "91/91 [==============================] - 89s 970ms/step - loss: 7.7926 - accuracy: 0.6336 - val_loss: 13.5616 - val_accuracy: 0.5412 - lr: 1.0000e-04\n",
      "Epoch 4/150\n",
      "91/91 [==============================] - 90s 982ms/step - loss: 5.8429 - accuracy: 0.6578 - val_loss: 5.4249 - val_accuracy: 0.6108 - lr: 1.0000e-04\n",
      "Epoch 5/150\n",
      "91/91 [==============================] - 89s 977ms/step - loss: 4.2870 - accuracy: 0.6806 - val_loss: 5.5216 - val_accuracy: 0.5952 - lr: 1.0000e-04\n",
      "Epoch 6/150\n",
      "91/91 [==============================] - 91s 993ms/step - loss: 3.0592 - accuracy: 0.7155 - val_loss: 3.0269 - val_accuracy: 0.7159 - lr: 1.0000e-04\n",
      "Epoch 7/150\n",
      "91/91 [==============================] - 89s 985ms/step - loss: 2.7189 - accuracy: 0.7175 - val_loss: 5.9958 - val_accuracy: 0.5639 - lr: 1.0000e-04\n",
      "Epoch 8/150\n",
      "91/91 [==============================] - 90s 989ms/step - loss: 2.2103 - accuracy: 0.7303 - val_loss: 3.0318 - val_accuracy: 0.6435 - lr: 1.0000e-04\n",
      "Epoch 9/150\n",
      "91/91 [==============================] - 89s 976ms/step - loss: 2.0100 - accuracy: 0.7272 - val_loss: 2.2567 - val_accuracy: 0.6818 - lr: 1.0000e-04\n",
      "Epoch 10/150\n",
      "91/91 [==============================] - 90s 979ms/step - loss: 1.7410 - accuracy: 0.7324 - val_loss: 4.7928 - val_accuracy: 0.5497 - lr: 1.0000e-04\n",
      "Epoch 11/150\n",
      "91/91 [==============================] - 88s 963ms/step - loss: 1.4144 - accuracy: 0.7552 - val_loss: 2.2798 - val_accuracy: 0.6847 - lr: 1.0000e-04\n",
      "Epoch 12/150\n",
      "91/91 [==============================] - 89s 972ms/step - loss: 1.3990 - accuracy: 0.7624 - val_loss: 1.3772 - val_accuracy: 0.7017 - lr: 1.0000e-04\n",
      "Epoch 13/150\n",
      "91/91 [==============================] - 89s 968ms/step - loss: 1.1083 - accuracy: 0.7818 - val_loss: 1.5718 - val_accuracy: 0.7173 - lr: 1.0000e-04\n",
      "Epoch 14/150\n",
      "91/91 [==============================] - 88s 966ms/step - loss: 1.0847 - accuracy: 0.7759 - val_loss: 2.2593 - val_accuracy: 0.7003 - lr: 1.0000e-04\n",
      "Epoch 15/150\n",
      "91/91 [==============================] - 89s 979ms/step - loss: 1.0011 - accuracy: 0.7901 - val_loss: 0.9987 - val_accuracy: 0.8125 - lr: 1.0000e-04\n",
      "Epoch 16/150\n",
      "91/91 [==============================] - 88s 964ms/step - loss: 1.0048 - accuracy: 0.7921 - val_loss: 1.5504 - val_accuracy: 0.6889 - lr: 1.0000e-04\n",
      "Epoch 17/150\n",
      "91/91 [==============================] - 89s 974ms/step - loss: 0.9513 - accuracy: 0.7883 - val_loss: 1.6831 - val_accuracy: 0.6463 - lr: 1.0000e-04\n",
      "Epoch 18/150\n",
      "91/91 [==============================] - 89s 970ms/step - loss: 0.7907 - accuracy: 0.8032 - val_loss: 1.5589 - val_accuracy: 0.6364 - lr: 1.0000e-04\n",
      "Epoch 19/150\n",
      "91/91 [==============================] - 89s 977ms/step - loss: 0.8159 - accuracy: 0.8066 - val_loss: 0.7557 - val_accuracy: 0.8381 - lr: 1.0000e-04\n",
      "Epoch 20/150\n",
      "91/91 [==============================] - 88s 968ms/step - loss: 0.8305 - accuracy: 0.8011 - val_loss: 1.8592 - val_accuracy: 0.6278 - lr: 1.0000e-04\n",
      "Epoch 21/150\n",
      "91/91 [==============================] - 88s 967ms/step - loss: 0.6643 - accuracy: 0.8187 - val_loss: 0.5720 - val_accuracy: 0.8310 - lr: 1.0000e-04\n",
      "Epoch 22/150\n",
      "91/91 [==============================] - 89s 969ms/step - loss: 0.7513 - accuracy: 0.8191 - val_loss: 0.7611 - val_accuracy: 0.7997 - lr: 1.0000e-04\n",
      "Epoch 23/150\n",
      "91/91 [==============================] - 89s 966ms/step - loss: 0.6834 - accuracy: 0.8260 - val_loss: 0.9973 - val_accuracy: 0.7443 - lr: 1.0000e-04\n",
      "Epoch 24/150\n",
      "91/91 [==============================] - 88s 967ms/step - loss: 0.6363 - accuracy: 0.8301 - val_loss: 1.4746 - val_accuracy: 0.6776 - lr: 1.0000e-04\n",
      "Epoch 25/150\n",
      "91/91 [==============================] - 89s 970ms/step - loss: 0.6561 - accuracy: 0.8305 - val_loss: 0.7874 - val_accuracy: 0.7955 - lr: 1.0000e-04\n",
      "Epoch 26/150\n",
      "91/91 [==============================] - 98s 1s/step - loss: 0.6541 - accuracy: 0.8128 - val_loss: 4.4752 - val_accuracy: 0.3864 - lr: 1.0000e-04\n",
      "Epoch 27/150\n",
      "91/91 [==============================] - 90s 980ms/step - loss: 0.6007 - accuracy: 0.8346 - val_loss: 0.6484 - val_accuracy: 0.8111 - lr: 1.0000e-04\n",
      "Epoch 28/150\n",
      "91/91 [==============================] - 88s 963ms/step - loss: 0.5256 - accuracy: 0.8470 - val_loss: 0.6502 - val_accuracy: 0.7969 - lr: 1.0000e-04\n",
      "Epoch 29/150\n",
      "91/91 [==============================] - 89s 970ms/step - loss: 0.5654 - accuracy: 0.8467 - val_loss: 0.7015 - val_accuracy: 0.7827 - lr: 1.0000e-04\n",
      "Epoch 30/150\n",
      "91/91 [==============================] - 89s 966ms/step - loss: 0.4951 - accuracy: 0.8550 - val_loss: 0.7122 - val_accuracy: 0.7855 - lr: 1.0000e-04\n",
      "Epoch 31/150\n",
      "91/91 [==============================] - 90s 984ms/step - loss: 0.4318 - accuracy: 0.8677 - val_loss: 0.4521 - val_accuracy: 0.8807 - lr: 5.0000e-05\n",
      "Epoch 32/150\n",
      "91/91 [==============================] - 89s 968ms/step - loss: 0.4050 - accuracy: 0.8695 - val_loss: 0.3950 - val_accuracy: 0.8807 - lr: 5.0000e-05\n",
      "Epoch 33/150\n",
      "91/91 [==============================] - 89s 969ms/step - loss: 0.3701 - accuracy: 0.8843 - val_loss: 0.4364 - val_accuracy: 0.8551 - lr: 5.0000e-05\n",
      "Epoch 34/150\n",
      "91/91 [==============================] - 88s 961ms/step - loss: 0.4105 - accuracy: 0.8688 - val_loss: 0.6349 - val_accuracy: 0.7969 - lr: 5.0000e-05\n",
      "Epoch 35/150\n",
      "91/91 [==============================] - 89s 975ms/step - loss: 0.4089 - accuracy: 0.8743 - val_loss: 0.3410 - val_accuracy: 0.8963 - lr: 5.0000e-05\n",
      "Epoch 36/150\n",
      "91/91 [==============================] - 89s 970ms/step - loss: 0.3567 - accuracy: 0.8871 - val_loss: 0.5005 - val_accuracy: 0.8608 - lr: 5.0000e-05\n",
      "Epoch 37/150\n",
      "91/91 [==============================] - 88s 964ms/step - loss: 0.3535 - accuracy: 0.8823 - val_loss: 0.3947 - val_accuracy: 0.8764 - lr: 5.0000e-05\n",
      "Epoch 38/150\n",
      "91/91 [==============================] - 88s 966ms/step - loss: 0.3549 - accuracy: 0.8871 - val_loss: 0.3733 - val_accuracy: 0.8736 - lr: 5.0000e-05\n",
      "Epoch 39/150\n",
      "91/91 [==============================] - 89s 968ms/step - loss: 0.3367 - accuracy: 0.8874 - val_loss: 0.4616 - val_accuracy: 0.8281 - lr: 5.0000e-05\n",
      "Epoch 40/150\n",
      "91/91 [==============================] - 88s 961ms/step - loss: 0.3387 - accuracy: 0.8874 - val_loss: 0.4932 - val_accuracy: 0.8352 - lr: 5.0000e-05\n",
      "Epoch 41/150\n",
      "91/91 [==============================] - 89s 967ms/step - loss: 0.3574 - accuracy: 0.8857 - val_loss: 0.4178 - val_accuracy: 0.8594 - lr: 5.0000e-05\n",
      "Epoch 42/150\n",
      "91/91 [==============================] - 88s 964ms/step - loss: 0.3638 - accuracy: 0.8867 - val_loss: 0.3325 - val_accuracy: 0.8807 - lr: 5.0000e-05\n",
      "Epoch 43/150\n",
      "91/91 [==============================] - 98s 1s/step - loss: 0.3466 - accuracy: 0.8874 - val_loss: 0.3195 - val_accuracy: 0.8878 - lr: 5.0000e-05\n",
      "Epoch 44/150\n",
      "91/91 [==============================] - 88s 966ms/step - loss: 0.3304 - accuracy: 0.8885 - val_loss: 0.5582 - val_accuracy: 0.8352 - lr: 5.0000e-05\n",
      "Epoch 45/150\n",
      "91/91 [==============================] - 88s 962ms/step - loss: 0.3387 - accuracy: 0.8874 - val_loss: 0.3731 - val_accuracy: 0.8849 - lr: 5.0000e-05\n",
      "Epoch 46/150\n",
      "91/91 [==============================] - 89s 970ms/step - loss: 0.3494 - accuracy: 0.8874 - val_loss: 0.3031 - val_accuracy: 0.8835 - lr: 5.0000e-05\n",
      "Epoch 47/150\n",
      "91/91 [==============================] - 89s 974ms/step - loss: 0.3232 - accuracy: 0.8947 - val_loss: 0.3227 - val_accuracy: 0.8963 - lr: 5.0000e-05\n",
      "Epoch 48/150\n",
      "91/91 [==============================] - 88s 959ms/step - loss: 0.3262 - accuracy: 0.8923 - val_loss: 0.5611 - val_accuracy: 0.8239 - lr: 5.0000e-05\n",
      "Epoch 49/150\n",
      "91/91 [==============================] - 88s 960ms/step - loss: 0.3178 - accuracy: 0.8957 - val_loss: 0.3571 - val_accuracy: 0.8849 - lr: 5.0000e-05\n",
      "Epoch 50/150\n",
      "91/91 [==============================] - 88s 964ms/step - loss: 0.3171 - accuracy: 0.8961 - val_loss: 0.3194 - val_accuracy: 0.8807 - lr: 5.0000e-05\n",
      "Epoch 51/150\n",
      "91/91 [==============================] - 88s 963ms/step - loss: 0.3167 - accuracy: 0.8905 - val_loss: 0.4632 - val_accuracy: 0.8523 - lr: 5.0000e-05\n",
      "Epoch 52/150\n",
      "91/91 [==============================] - 88s 962ms/step - loss: 0.3400 - accuracy: 0.8833 - val_loss: 0.3059 - val_accuracy: 0.8935 - lr: 5.0000e-05\n",
      "Epoch 53/150\n",
      "91/91 [==============================] - 89s 969ms/step - loss: 0.3217 - accuracy: 0.8947 - val_loss: 0.3747 - val_accuracy: 0.9020 - lr: 5.0000e-05\n",
      "Epoch 54/150\n",
      "91/91 [==============================] - 88s 964ms/step - loss: 0.3121 - accuracy: 0.8919 - val_loss: 0.3153 - val_accuracy: 0.8892 - lr: 5.0000e-05\n",
      "Epoch 55/150\n",
      "91/91 [==============================] - 88s 958ms/step - loss: 0.3032 - accuracy: 0.8999 - val_loss: 0.4098 - val_accuracy: 0.8722 - lr: 5.0000e-05\n",
      "Epoch 56/150\n",
      "91/91 [==============================] - 87s 956ms/step - loss: 0.3174 - accuracy: 0.8909 - val_loss: 0.3881 - val_accuracy: 0.8835 - lr: 5.0000e-05\n",
      "Epoch 57/150\n",
      "91/91 [==============================] - 88s 968ms/step - loss: 0.3125 - accuracy: 0.8974 - val_loss: 0.3256 - val_accuracy: 0.9006 - lr: 5.0000e-05\n",
      "Epoch 58/150\n",
      "91/91 [==============================] - 88s 962ms/step - loss: 0.2836 - accuracy: 0.9016 - val_loss: 0.3323 - val_accuracy: 0.8793 - lr: 5.0000e-05\n",
      "Epoch 59/150\n",
      "91/91 [==============================] - 88s 961ms/step - loss: 0.2971 - accuracy: 0.9030 - val_loss: 0.3377 - val_accuracy: 0.8707 - lr: 5.0000e-05\n",
      "Epoch 60/150\n",
      "91/91 [==============================] - 88s 959ms/step - loss: 0.2960 - accuracy: 0.9030 - val_loss: 0.3663 - val_accuracy: 0.8849 - lr: 5.0000e-05\n",
      "Epoch 61/150\n",
      "91/91 [==============================] - 88s 957ms/step - loss: 0.2812 - accuracy: 0.9050 - val_loss: 0.4222 - val_accuracy: 0.8693 - lr: 2.5000e-05\n",
      "Epoch 62/150\n",
      "91/91 [==============================] - 97s 1s/step - loss: 0.2769 - accuracy: 0.9085 - val_loss: 0.3674 - val_accuracy: 0.8864 - lr: 2.5000e-05\n",
      "Epoch 63/150\n",
      "91/91 [==============================] - 88s 959ms/step - loss: 0.2795 - accuracy: 0.9075 - val_loss: 0.3900 - val_accuracy: 0.8594 - lr: 2.5000e-05\n",
      "Epoch 64/150\n",
      "91/91 [==============================] - 88s 968ms/step - loss: 0.2663 - accuracy: 0.9071 - val_loss: 0.4033 - val_accuracy: 0.8480 - lr: 2.5000e-05\n",
      "Epoch 65/150\n",
      "91/91 [==============================] - 88s 966ms/step - loss: 0.2763 - accuracy: 0.9088 - val_loss: 0.2817 - val_accuracy: 0.9048 - lr: 2.5000e-05\n",
      "Epoch 66/150\n",
      "91/91 [==============================] - 88s 960ms/step - loss: 0.2669 - accuracy: 0.9075 - val_loss: 0.3378 - val_accuracy: 0.8793 - lr: 2.5000e-05\n",
      "Epoch 67/150\n",
      "91/91 [==============================] - 88s 965ms/step - loss: 0.2649 - accuracy: 0.9133 - val_loss: 0.3031 - val_accuracy: 0.8849 - lr: 2.5000e-05\n",
      "Epoch 68/150\n",
      "91/91 [==============================] - 88s 958ms/step - loss: 0.2752 - accuracy: 0.9068 - val_loss: 0.2678 - val_accuracy: 0.8991 - lr: 2.5000e-05\n",
      "Epoch 69/150\n",
      "91/91 [==============================] - 88s 959ms/step - loss: 0.2677 - accuracy: 0.9047 - val_loss: 0.2876 - val_accuracy: 0.8935 - lr: 2.5000e-05\n",
      "Epoch 70/150\n",
      "91/91 [==============================] - 87s 956ms/step - loss: 0.2557 - accuracy: 0.9078 - val_loss: 0.2759 - val_accuracy: 0.8991 - lr: 2.5000e-05\n",
      "Epoch 71/150\n",
      "91/91 [==============================] - 88s 961ms/step - loss: 0.2722 - accuracy: 0.9023 - val_loss: 0.2866 - val_accuracy: 0.8963 - lr: 2.5000e-05\n",
      "Epoch 72/150\n",
      "91/91 [==============================] - 87s 950ms/step - loss: 0.2602 - accuracy: 0.9161 - val_loss: 0.2854 - val_accuracy: 0.8977 - lr: 2.5000e-05\n",
      "Epoch 73/150\n",
      "91/91 [==============================] - 87s 951ms/step - loss: 0.2662 - accuracy: 0.9088 - val_loss: 0.2981 - val_accuracy: 0.8778 - lr: 2.5000e-05\n",
      "Epoch 74/150\n",
      "91/91 [==============================] - 88s 958ms/step - loss: 0.2642 - accuracy: 0.9092 - val_loss: 0.3068 - val_accuracy: 0.8835 - lr: 2.5000e-05\n",
      "Epoch 75/150\n",
      "91/91 [==============================] - 88s 960ms/step - loss: 0.2665 - accuracy: 0.9154 - val_loss: 0.2731 - val_accuracy: 0.9020 - lr: 2.5000e-05\n",
      "Epoch 76/150\n",
      "91/91 [==============================] - 87s 956ms/step - loss: 0.2660 - accuracy: 0.9099 - val_loss: 0.2594 - val_accuracy: 0.9006 - lr: 2.5000e-05\n",
      "Epoch 77/150\n",
      "91/91 [==============================] - 87s 954ms/step - loss: 0.2773 - accuracy: 0.9061 - val_loss: 0.3764 - val_accuracy: 0.8778 - lr: 2.5000e-05\n",
      "Epoch 78/150\n",
      "91/91 [==============================] - 88s 958ms/step - loss: 0.2519 - accuracy: 0.9157 - val_loss: 0.3017 - val_accuracy: 0.8892 - lr: 2.5000e-05\n",
      "Epoch 79/150\n",
      "91/91 [==============================] - 89s 976ms/step - loss: 0.2569 - accuracy: 0.9095 - val_loss: 0.2906 - val_accuracy: 0.9062 - lr: 2.5000e-05\n",
      "Epoch 80/150\n",
      "91/91 [==============================] - 88s 965ms/step - loss: 0.2631 - accuracy: 0.9047 - val_loss: 0.2608 - val_accuracy: 0.9105 - lr: 2.5000e-05\n",
      "Epoch 81/150\n",
      "91/91 [==============================] - 88s 965ms/step - loss: 0.2602 - accuracy: 0.9081 - val_loss: 0.3290 - val_accuracy: 0.8722 - lr: 2.5000e-05\n",
      "Epoch 82/150\n",
      "91/91 [==============================] - 87s 955ms/step - loss: 0.2591 - accuracy: 0.9085 - val_loss: 0.2975 - val_accuracy: 0.8920 - lr: 2.5000e-05\n",
      "Epoch 83/150\n",
      "91/91 [==============================] - 88s 961ms/step - loss: 0.2620 - accuracy: 0.9078 - val_loss: 0.3616 - val_accuracy: 0.8693 - lr: 2.5000e-05\n",
      "Epoch 84/150\n",
      "91/91 [==============================] - 88s 959ms/step - loss: 0.2602 - accuracy: 0.9116 - val_loss: 0.3117 - val_accuracy: 0.8977 - lr: 2.5000e-05\n",
      "Epoch 85/150\n",
      "91/91 [==============================] - 87s 956ms/step - loss: 0.2698 - accuracy: 0.9102 - val_loss: 0.2588 - val_accuracy: 0.8949 - lr: 2.5000e-05\n",
      "Epoch 86/150\n",
      "91/91 [==============================] - 88s 955ms/step - loss: 0.2556 - accuracy: 0.9123 - val_loss: 0.2758 - val_accuracy: 0.9091 - lr: 2.5000e-05\n",
      "Epoch 87/150\n",
      "91/91 [==============================] - 87s 949ms/step - loss: 0.2606 - accuracy: 0.9109 - val_loss: 0.3728 - val_accuracy: 0.8537 - lr: 2.5000e-05\n",
      "Epoch 88/150\n",
      "91/91 [==============================] - 87s 955ms/step - loss: 0.2623 - accuracy: 0.9116 - val_loss: 0.2724 - val_accuracy: 0.9034 - lr: 2.5000e-05\n",
      "Epoch 89/150\n",
      "91/91 [==============================] - 87s 957ms/step - loss: 0.2698 - accuracy: 0.9130 - val_loss: 0.3148 - val_accuracy: 0.8764 - lr: 2.5000e-05\n",
      "Epoch 90/150\n",
      "91/91 [==============================] - 87s 957ms/step - loss: 0.2595 - accuracy: 0.9133 - val_loss: 0.3644 - val_accuracy: 0.8636 - lr: 2.5000e-05\n",
      "Epoch 91/150\n",
      "91/91 [==============================] - 88s 959ms/step - loss: 0.2691 - accuracy: 0.9123 - val_loss: 0.2571 - val_accuracy: 0.9105 - lr: 1.2500e-05\n",
      "Epoch 92/150\n",
      "91/91 [==============================] - 88s 959ms/step - loss: 0.2218 - accuracy: 0.9168 - val_loss: 0.2683 - val_accuracy: 0.9020 - lr: 1.2500e-05\n",
      "Epoch 93/150\n",
      "91/91 [==============================] - 87s 956ms/step - loss: 0.2485 - accuracy: 0.9109 - val_loss: 0.2506 - val_accuracy: 0.9062 - lr: 1.2500e-05\n",
      "Epoch 94/150\n",
      "91/91 [==============================] - 87s 947ms/step - loss: 0.2525 - accuracy: 0.9192 - val_loss: 0.2529 - val_accuracy: 0.9077 - lr: 1.2500e-05\n",
      "Epoch 95/150\n",
      "91/91 [==============================] - 88s 965ms/step - loss: 0.2490 - accuracy: 0.9168 - val_loss: 0.2938 - val_accuracy: 0.8849 - lr: 1.2500e-05\n",
      "Epoch 96/150\n",
      "91/91 [==============================] - 89s 969ms/step - loss: 0.2531 - accuracy: 0.9109 - val_loss: 0.2664 - val_accuracy: 0.9006 - lr: 1.2500e-05\n",
      "Epoch 97/150\n",
      "91/91 [==============================] - 89s 974ms/step - loss: 0.2437 - accuracy: 0.9161 - val_loss: 0.2730 - val_accuracy: 0.9048 - lr: 1.2500e-05\n",
      "Epoch 98/150\n",
      "91/91 [==============================] - 88s 965ms/step - loss: 0.2597 - accuracy: 0.9185 - val_loss: 0.2599 - val_accuracy: 0.9062 - lr: 1.2500e-05\n",
      "Epoch 99/150\n",
      "91/91 [==============================] - 89s 969ms/step - loss: 0.2448 - accuracy: 0.9199 - val_loss: 0.2725 - val_accuracy: 0.9020 - lr: 1.2500e-05\n",
      "Epoch 100/150\n",
      "91/91 [==============================] - 88s 958ms/step - loss: 0.2405 - accuracy: 0.9185 - val_loss: 0.2977 - val_accuracy: 0.8920 - lr: 1.2500e-05\n",
      "Epoch 101/150\n",
      "91/91 [==============================] - 89s 978ms/step - loss: 0.2383 - accuracy: 0.9157 - val_loss: 0.2701 - val_accuracy: 0.9034 - lr: 1.2500e-05\n",
      "Epoch 102/150\n",
      "91/91 [==============================] - 91s 996ms/step - loss: 0.2465 - accuracy: 0.9189 - val_loss: 0.2960 - val_accuracy: 0.8864 - lr: 1.2500e-05\n",
      "Epoch 103/150\n",
      "91/91 [==============================] - 90s 983ms/step - loss: 0.2388 - accuracy: 0.9237 - val_loss: 0.2525 - val_accuracy: 0.9134 - lr: 1.2500e-05\n",
      "Epoch 104/150\n",
      "91/91 [==============================] - 89s 972ms/step - loss: 0.2338 - accuracy: 0.9216 - val_loss: 0.2622 - val_accuracy: 0.9134 - lr: 1.2500e-05\n",
      "Epoch 105/150\n",
      "91/91 [==============================] - 88s 959ms/step - loss: 0.2413 - accuracy: 0.9168 - val_loss: 0.3026 - val_accuracy: 0.8864 - lr: 1.2500e-05\n",
      "Epoch 106/150\n",
      "91/91 [==============================] - 86s 945ms/step - loss: 0.2369 - accuracy: 0.9202 - val_loss: 0.2622 - val_accuracy: 0.9048 - lr: 1.2500e-05\n",
      "Epoch 107/150\n",
      "91/91 [==============================] - 87s 953ms/step - loss: 0.2296 - accuracy: 0.9185 - val_loss: 0.2588 - val_accuracy: 0.9077 - lr: 1.2500e-05\n",
      "Epoch 108/150\n",
      "91/91 [==============================] - 87s 955ms/step - loss: 0.2391 - accuracy: 0.9206 - val_loss: 0.2510 - val_accuracy: 0.9119 - lr: 1.2500e-05\n",
      "Epoch 109/150\n",
      "91/91 [==============================] - 90s 979ms/step - loss: 0.2538 - accuracy: 0.9182 - val_loss: 0.2576 - val_accuracy: 0.9062 - lr: 1.2500e-05\n",
      "Epoch 110/150\n",
      "91/91 [==============================] - 87s 956ms/step - loss: 0.2539 - accuracy: 0.9126 - val_loss: 0.2516 - val_accuracy: 0.9077 - lr: 1.2500e-05\n",
      "Epoch 111/150\n",
      "91/91 [==============================] - 87s 954ms/step - loss: 0.2261 - accuracy: 0.9223 - val_loss: 0.2854 - val_accuracy: 0.8906 - lr: 1.2500e-05\n",
      "Epoch 112/150\n",
      "91/91 [==============================] - 88s 958ms/step - loss: 0.2418 - accuracy: 0.9178 - val_loss: 0.2811 - val_accuracy: 0.8977 - lr: 1.2500e-05\n",
      "Epoch 113/150\n",
      "91/91 [==============================] - 89s 972ms/step - loss: 0.2345 - accuracy: 0.9271 - val_loss: 0.2579 - val_accuracy: 0.9091 - lr: 1.2500e-05\n",
      "Epoch 114/150\n",
      "91/91 [==============================] - 87s 951ms/step - loss: 0.2405 - accuracy: 0.9171 - val_loss: 0.2582 - val_accuracy: 0.9077 - lr: 1.2500e-05\n",
      "Epoch 115/150\n",
      "91/91 [==============================] - 89s 974ms/step - loss: 0.2366 - accuracy: 0.9209 - val_loss: 0.2563 - val_accuracy: 0.9119 - lr: 1.2500e-05\n",
      "Epoch 116/150\n",
      "91/91 [==============================] - 87s 952ms/step - loss: 0.2446 - accuracy: 0.9220 - val_loss: 0.2552 - val_accuracy: 0.9105 - lr: 1.2500e-05\n",
      "Epoch 117/150\n",
      "91/91 [==============================] - 89s 979ms/step - loss: 0.2364 - accuracy: 0.9157 - val_loss: 0.2484 - val_accuracy: 0.9119 - lr: 1.2500e-05\n",
      "Epoch 118/150\n",
      "91/91 [==============================] - 91s 997ms/step - loss: 0.2310 - accuracy: 0.9237 - val_loss: 0.2479 - val_accuracy: 0.9062 - lr: 1.2500e-05\n",
      "Epoch 119/150\n",
      "91/91 [==============================] - 92s 1s/step - loss: 0.2435 - accuracy: 0.9168 - val_loss: 0.2439 - val_accuracy: 0.9148 - lr: 1.2500e-05\n",
      "Epoch 120/150\n",
      "91/91 [==============================] - 90s 980ms/step - loss: 0.2418 - accuracy: 0.9209 - val_loss: 0.2824 - val_accuracy: 0.9006 - lr: 1.2500e-05\n",
      "Epoch 121/150\n",
      "91/91 [==============================] - 88s 962ms/step - loss: 0.2276 - accuracy: 0.9164 - val_loss: 0.2542 - val_accuracy: 0.9034 - lr: 6.2500e-06\n",
      "Epoch 122/150\n",
      "91/91 [==============================] - 89s 976ms/step - loss: 0.2273 - accuracy: 0.9230 - val_loss: 0.2564 - val_accuracy: 0.9077 - lr: 6.2500e-06\n",
      "Epoch 123/150\n",
      "91/91 [==============================] - 90s 981ms/step - loss: 0.2093 - accuracy: 0.9230 - val_loss: 0.2514 - val_accuracy: 0.9091 - lr: 6.2500e-06\n",
      "Epoch 124/150\n",
      "91/91 [==============================] - 90s 985ms/step - loss: 0.2201 - accuracy: 0.9237 - val_loss: 0.2434 - val_accuracy: 0.9162 - lr: 6.2500e-06\n",
      "Epoch 125/150\n",
      "91/91 [==============================] - 89s 974ms/step - loss: 0.2322 - accuracy: 0.9223 - val_loss: 0.2468 - val_accuracy: 0.9162 - lr: 6.2500e-06\n",
      "Epoch 126/150\n",
      "91/91 [==============================] - 89s 974ms/step - loss: 0.2260 - accuracy: 0.9192 - val_loss: 0.2650 - val_accuracy: 0.9048 - lr: 6.2500e-06\n",
      "Epoch 127/150\n",
      "91/91 [==============================] - 89s 972ms/step - loss: 0.2329 - accuracy: 0.9195 - val_loss: 0.2666 - val_accuracy: 0.9006 - lr: 6.2500e-06\n",
      "Epoch 128/150\n",
      "91/91 [==============================] - 89s 975ms/step - loss: 0.2198 - accuracy: 0.9251 - val_loss: 0.2649 - val_accuracy: 0.9034 - lr: 6.2500e-06\n",
      "Epoch 129/150\n",
      "91/91 [==============================] - 90s 982ms/step - loss: 0.2328 - accuracy: 0.9157 - val_loss: 0.2759 - val_accuracy: 0.9006 - lr: 6.2500e-06\n",
      "Epoch 130/150\n",
      "91/91 [==============================] - 90s 983ms/step - loss: 0.2204 - accuracy: 0.9251 - val_loss: 0.2852 - val_accuracy: 0.8920 - lr: 6.2500e-06\n",
      "Epoch 131/150\n",
      "91/91 [==============================] - 89s 979ms/step - loss: 0.2370 - accuracy: 0.9168 - val_loss: 0.2377 - val_accuracy: 0.9091 - lr: 6.2500e-06\n",
      "Epoch 132/150\n",
      "91/91 [==============================] - 91s 993ms/step - loss: 0.2158 - accuracy: 0.9261 - val_loss: 0.2560 - val_accuracy: 0.9105 - lr: 6.2500e-06\n",
      "Epoch 133/150\n",
      "91/91 [==============================] - 88s 960ms/step - loss: 0.2199 - accuracy: 0.9230 - val_loss: 0.2660 - val_accuracy: 0.9034 - lr: 6.2500e-06\n",
      "Epoch 134/150\n",
      "91/91 [==============================] - 88s 959ms/step - loss: 0.2201 - accuracy: 0.9292 - val_loss: 0.2685 - val_accuracy: 0.9034 - lr: 6.2500e-06\n",
      "Epoch 135/150\n",
      "91/91 [==============================] - 87s 953ms/step - loss: 0.2268 - accuracy: 0.9223 - val_loss: 0.2462 - val_accuracy: 0.9162 - lr: 6.2500e-06\n",
      "Epoch 136/150\n",
      "91/91 [==============================] - 87s 949ms/step - loss: 0.2296 - accuracy: 0.9240 - val_loss: 0.2520 - val_accuracy: 0.9119 - lr: 6.2500e-06\n",
      "Epoch 137/150\n",
      "91/91 [==============================] - 88s 962ms/step - loss: 0.2317 - accuracy: 0.9168 - val_loss: 0.2420 - val_accuracy: 0.9162 - lr: 6.2500e-06\n",
      "Epoch 138/150\n",
      "91/91 [==============================] - 88s 959ms/step - loss: 0.2342 - accuracy: 0.9175 - val_loss: 0.2516 - val_accuracy: 0.9091 - lr: 6.2500e-06\n",
      "Epoch 139/150\n",
      "91/91 [==============================] - 88s 968ms/step - loss: 0.2237 - accuracy: 0.9285 - val_loss: 0.2609 - val_accuracy: 0.9034 - lr: 6.2500e-06\n",
      "Epoch 140/150\n",
      "91/91 [==============================] - 88s 961ms/step - loss: 0.2404 - accuracy: 0.9213 - val_loss: 0.2884 - val_accuracy: 0.8977 - lr: 6.2500e-06\n",
      "Epoch 141/150\n",
      "91/91 [==============================] - 87s 950ms/step - loss: 0.2302 - accuracy: 0.9209 - val_loss: 0.2581 - val_accuracy: 0.9077 - lr: 6.2500e-06\n",
      "Epoch 142/150\n",
      "91/91 [==============================] - 87s 952ms/step - loss: 0.2270 - accuracy: 0.9251 - val_loss: 0.2551 - val_accuracy: 0.9105 - lr: 6.2500e-06\n",
      "Epoch 143/150\n",
      "91/91 [==============================] - 87s 952ms/step - loss: 0.2027 - accuracy: 0.9258 - val_loss: 0.2576 - val_accuracy: 0.9105 - lr: 6.2500e-06\n",
      "Epoch 144/150\n",
      "91/91 [==============================] - 88s 960ms/step - loss: 0.2321 - accuracy: 0.9265 - val_loss: 0.2566 - val_accuracy: 0.9062 - lr: 6.2500e-06\n",
      "Epoch 145/150\n",
      "91/91 [==============================] - 87s 956ms/step - loss: 0.2225 - accuracy: 0.9258 - val_loss: 0.2578 - val_accuracy: 0.9034 - lr: 6.2500e-06\n",
      "Epoch 146/150\n",
      "91/91 [==============================] - 87s 951ms/step - loss: 0.2217 - accuracy: 0.9254 - val_loss: 0.2609 - val_accuracy: 0.9034 - lr: 6.2500e-06\n",
      "Epoch 147/150\n",
      "91/91 [==============================] - 87s 955ms/step - loss: 0.2152 - accuracy: 0.9282 - val_loss: 0.2572 - val_accuracy: 0.9034 - lr: 6.2500e-06\n",
      "Epoch 148/150\n",
      "91/91 [==============================] - 87s 956ms/step - loss: 0.2222 - accuracy: 0.9185 - val_loss: 0.2499 - val_accuracy: 0.9091 - lr: 6.2500e-06\n",
      "Epoch 149/150\n",
      "91/91 [==============================] - 89s 976ms/step - loss: 0.2285 - accuracy: 0.9261 - val_loss: 0.2425 - val_accuracy: 0.9134 - lr: 6.2500e-06\n",
      "Epoch 150/150\n",
      "91/91 [==============================] - 91s 994ms/step - loss: 0.2147 - accuracy: 0.9265 - val_loss: 0.2525 - val_accuracy: 0.9119 - lr: 6.2500e-06\n",
      "Total run time = 235.79 min \n"
     ]
    }
   ],
   "source": [
    "checkpoint_filepath =  '/content/atten'\n",
    "opt = SGD(\n",
    "    learning_rate=0.0001,\n",
    "    momentum=0.9,\n",
    "    nesterov=True,\n",
    "    weight_decay=0.0001)\n",
    "\n",
    "from time import time\n",
    "start = time()\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "  history_atten,model3 = train(train_dataset, model,'attenresnet',\n",
    "           train_steps,\n",
    "           validation_dataset,\n",
    "           validation_steps,\n",
    "           checkpoint_filepath,\n",
    "           epoch=150,\n",
    "           opt = opt)\n",
    "\n",
    "print('Total run time = {:.2f} min '.format((time()-start)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w67iXX3xAtBu"
   },
   "source": [
    "### model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o6WxGxInApQb",
    "outputId": "f11f93e5-9dc8-4989-e7b2-011b9caa4251"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 112, 112, 32  4736        ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 56, 56, 32)   0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 56, 56, 32)  128         ['max_pooling2d[0][0]']          \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 56, 56, 32)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 56, 56, 16)   528         ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 56, 56, 16)  64          ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 56, 56, 16)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 56, 56, 16)   2320        ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 56, 56, 16)  64          ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 56, 56, 16)   0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 56, 56, 64)   2112        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 56, 56, 64)   1088        ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 56, 56, 64)   0           ['conv2d_4[0][0]',               \n",
      "                                                                  'conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 56, 56, 64)  256         ['add[0][0]']                    \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 56, 56, 64)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 56, 56, 16)   1040        ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 56, 16)  64          ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 56, 56, 16)   0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 56, 56, 16)   2320        ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 56, 56, 16)  64          ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 56, 56, 16)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 56, 56, 64)   1088        ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 56, 56, 64)   0           ['add[0][0]',                    \n",
      "                                                                  'conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 28, 28, 64)  0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 28, 28, 64)  256         ['max_pooling2d_1[0][0]']        \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 28, 28, 64)   0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 28, 28, 16)   1040        ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 28, 28, 16)  64          ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 28, 28, 16)   0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 28, 28, 16)   2320        ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 28, 28, 16)  64          ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 28, 28, 16)   0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 28, 28, 64)   1088        ['activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 28, 28, 64)   0           ['max_pooling2d_1[0][0]',        \n",
      "                                                                  'conv2d_16[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 64)  0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 14, 14, 64)  256         ['max_pooling2d_2[0][0]']        \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 14, 14, 64)   0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 14, 14, 16)   1040        ['activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 14, 14, 16)  64          ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 14, 14, 16)   0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 14, 14, 16)   2320        ['activation_19[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 14, 14, 16)  64          ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 14, 14, 16)   0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 14, 14, 64)   1088        ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 14, 14, 64)   0           ['max_pooling2d_2[0][0]',        \n",
      "                                                                  'conv2d_22[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 7, 7, 64)    0           ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 7, 7, 64)    256         ['max_pooling2d_3[0][0]']        \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 7, 7, 64)     0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 7, 7, 16)     1040        ['activation_24[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 7, 7, 16)    64          ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 7, 7, 16)     0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 7, 7, 16)     2320        ['activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 7, 7, 16)    64          ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 7, 7, 16)     0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 7, 7, 64)     1088        ['activation_26[0][0]']          \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 7, 7, 64)     0           ['max_pooling2d_3[0][0]',        \n",
      "                                                                  'conv2d_28[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 7, 7, 64)    256         ['add_8[0][0]']                  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 7, 7, 64)     0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 14, 14, 64)  256         ['add_6[0][0]']                  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 7, 7, 16)     1040        ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 14, 14, 64)   0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 7, 7, 16)    64          ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 14, 14, 16)   1040        ['activation_21[0][0]']          \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 7, 7, 16)     0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 14, 14, 16)  64          ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 7, 7, 16)     2320        ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 14, 14, 16)   0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 7, 7, 16)    64          ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 14, 14, 16)   2320        ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 7, 7, 16)     0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 14, 14, 16)  64          ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 7, 7, 64)     1088        ['activation_29[0][0]']          \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 14, 14, 16)   0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 7, 7, 64)     0           ['add_8[0][0]',                  \n",
      "                                                                  'conv2d_31[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 14, 14, 64)   1088        ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 14, 14, 64)   0           ['add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 14, 14, 64)   0           ['add_6[0][0]',                  \n",
      "                                                                  'conv2d_25[0][0]']              \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 14, 14, 64)   0           ['up_sampling2d[0][0]',          \n",
      "                                                                  'add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 14, 14, 64)  256         ['add_10[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 14, 14, 64)   0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 28, 28, 64)  256         ['add_4[0][0]']                  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 14, 14, 16)   1040        ['activation_30[0][0]']          \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 28, 28, 64)   0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 14, 14, 16)  64          ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 28, 28, 16)   1040        ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 14, 14, 16)   0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 28, 28, 16)  64          ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 14, 14, 16)   2320        ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 28, 28, 16)   0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 14, 14, 16)  64          ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 28, 28, 16)   2320        ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 14, 14, 16)   0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 28, 28, 16)  64          ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 56, 56, 64)  256         ['add_1[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 14, 14, 64)   1088        ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 28, 28, 16)   0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 56, 56, 64)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 14, 14, 64)   0           ['add_10[0][0]',                 \n",
      "                                                                  'conv2d_34[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 28, 28, 64)   1088        ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 56, 56, 16)   1040        ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSampling2D)  (None, 28, 28, 64)  0           ['add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 28, 28, 64)   0           ['add_4[0][0]',                  \n",
      "                                                                  'conv2d_19[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 56, 56, 16)  64          ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 28, 28, 64)   0           ['up_sampling2d_1[0][0]',        \n",
      "                                                                  'add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 56, 56, 16)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 28, 28, 64)  256         ['add_12[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 56, 56, 16)   2320        ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 28, 28, 64)   0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 56, 56, 16)  64          ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 28, 28, 16)   1040        ['activation_33[0][0]']          \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 56, 56, 16)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 28, 28, 16)  64          ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 56, 56, 64)   1088        ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 28, 28, 16)   0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 56, 56, 64)   0           ['add_1[0][0]',                  \n",
      "                                                                  'conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 28, 28, 16)   2320        ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 56, 56, 64)  256         ['add_2[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 28, 28, 16)  64          ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 56, 56, 64)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 28, 28, 16)   0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 56, 56, 16)   1040        ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 28, 28, 64)   1088        ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 56, 56, 16)  64          ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 28, 28, 64)   0           ['add_12[0][0]',                 \n",
      "                                                                  'conv2d_37[0][0]']              \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 56, 56, 16)   0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSampling2D)  (None, 56, 56, 64)  0           ['add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 56, 56, 16)   2320        ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 56, 56, 64)   4160        ['up_sampling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 56, 56, 16)  64          ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 56, 56, 64)   4160        ['conv2d_38[0][0]']              \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 56, 56, 16)   0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 56, 56, 64)   0           ['conv2d_39[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 56, 56, 64)   1088        ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 56, 56, 64)   0           ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 56, 56, 64)   0           ['add_2[0][0]',                  \n",
      "                                                                  'conv2d_13[0][0]']              \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, 56, 56, 64)   0           ['lambda[0][0]',                 \n",
      "                                                                  'add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 56, 56, 64)  256         ['multiply[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 56, 56, 64)   0           ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 56, 56, 16)   1040        ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 56, 56, 16)  64          ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 56, 56, 16)   0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 56, 56, 16)   2320        ['activation_38[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 56, 56, 16)  64          ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 56, 56, 16)   0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 56, 56, 64)   1088        ['activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 56, 56, 64)   0           ['multiply[0][0]',               \n",
      "                                                                  'conv2d_42[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 56, 56, 64)  256         ['add_14[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 56, 56, 64)   0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 56, 56, 32)   2080        ['activation_40[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 56, 56, 32)  128         ['conv2d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 56, 56, 32)   0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 56, 56, 32)   9248        ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 56, 56, 32)  128         ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 56, 56, 32)   0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 56, 56, 128)  8320        ['add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 56, 56, 128)  4224        ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 56, 56, 128)  0           ['conv2d_46[0][0]',              \n",
      "                                                                  'conv2d_45[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 56, 56, 128)  512        ['add_15[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 56, 56, 128)  0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 56, 56, 32)   4128        ['activation_43[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 56, 56, 32)  128         ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 56, 56, 32)   0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 56, 56, 32)   9248        ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 56, 56, 32)  128         ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 56, 56, 32)   0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 56, 56, 128)  4224        ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " add_16 (Add)                   (None, 56, 56, 128)  0           ['add_15[0][0]',                 \n",
      "                                                                  'conv2d_49[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 28, 28, 128)  0          ['add_16[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 28, 28, 128)  512        ['max_pooling2d_4[0][0]']        \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 28, 28, 32)   4128        ['activation_52[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 28, 28, 32)  128         ['conv2d_56[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 28, 28, 32)   0           ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 28, 28, 32)   9248        ['activation_53[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 28, 28, 32)  128         ['conv2d_57[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, 28, 28, 32)   0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 28, 28, 128)  4224        ['activation_54[0][0]']          \n",
      "                                                                                                  \n",
      " add_19 (Add)                   (None, 28, 28, 128)  0           ['max_pooling2d_4[0][0]',        \n",
      "                                                                  'conv2d_58[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 14, 14, 128)  0          ['add_19[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 14, 14, 128)  512        ['max_pooling2d_5[0][0]']        \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_58 (Activation)     (None, 14, 14, 128)  0           ['batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 14, 14, 32)   4128        ['activation_58[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 14, 14, 32)  128         ['conv2d_62[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_59 (Activation)     (None, 14, 14, 32)   0           ['batch_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 14, 14, 32)   9248        ['activation_59[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, 14, 14, 32)  128         ['conv2d_63[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_60 (Activation)     (None, 14, 14, 32)   0           ['batch_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)             (None, 14, 14, 128)  4224        ['activation_60[0][0]']          \n",
      "                                                                                                  \n",
      " add_21 (Add)                   (None, 14, 14, 128)  0           ['max_pooling2d_5[0][0]',        \n",
      "                                                                  'conv2d_64[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_60 (BatchN  (None, 14, 14, 128)  512        ['add_21[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_61 (Activation)     (None, 14, 14, 128)  0           ['batch_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 28, 28, 128)  512        ['add_19[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)             (None, 14, 14, 32)   4128        ['activation_61[0][0]']          \n",
      "                                                                                                  \n",
      " activation_55 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_61 (BatchN  (None, 14, 14, 32)  128         ['conv2d_65[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)             (None, 28, 28, 32)   4128        ['activation_55[0][0]']          \n",
      "                                                                                                  \n",
      " activation_62 (Activation)     (None, 14, 14, 32)   0           ['batch_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 28, 28, 32)  128         ['conv2d_59[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)             (None, 14, 14, 32)   9248        ['activation_62[0][0]']          \n",
      "                                                                                                  \n",
      " activation_56 (Activation)     (None, 28, 28, 32)   0           ['batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_62 (BatchN  (None, 14, 14, 32)  128         ['conv2d_66[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)             (None, 28, 28, 32)   9248        ['activation_56[0][0]']          \n",
      "                                                                                                  \n",
      " activation_63 (Activation)     (None, 14, 14, 32)   0           ['batch_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 28, 28, 32)  128         ['conv2d_60[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 56, 56, 128)  512        ['add_16[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)             (None, 14, 14, 128)  4224        ['activation_63[0][0]']          \n",
      "                                                                                                  \n",
      " activation_57 (Activation)     (None, 28, 28, 32)   0           ['batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 56, 56, 128)  0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " add_22 (Add)                   (None, 14, 14, 128)  0           ['add_21[0][0]',                 \n",
      "                                                                  'conv2d_67[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 28, 28, 128)  4224        ['activation_57[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 56, 56, 32)   4128        ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSampling2D)  (None, 28, 28, 128)  0          ['add_22[0][0]']                 \n",
      "                                                                                                  \n",
      " add_20 (Add)                   (None, 28, 28, 128)  0           ['add_19[0][0]',                 \n",
      "                                                                  'conv2d_61[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 56, 56, 32)  128         ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_23 (Add)                   (None, 28, 28, 128)  0           ['up_sampling2d_3[0][0]',        \n",
      "                                                                  'add_20[0][0]']                 \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 56, 56, 32)   0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_63 (BatchN  (None, 28, 28, 128)  512        ['add_23[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 56, 56, 32)   9248        ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " activation_64 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 56, 56, 32)  128         ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)             (None, 28, 28, 32)   4128        ['activation_64[0][0]']          \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 56, 56, 32)   0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_64 (BatchN  (None, 28, 28, 32)  128         ['conv2d_68[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 56, 56, 128)  4224        ['activation_48[0][0]']          \n",
      "                                                                                                  \n",
      " activation_65 (Activation)     (None, 28, 28, 32)   0           ['batch_normalization_64[0][0]'] \n",
      "                                                                                                  \n",
      " add_17 (Add)                   (None, 56, 56, 128)  0           ['add_16[0][0]',                 \n",
      "                                                                  'conv2d_52[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)             (None, 28, 28, 32)   9248        ['activation_65[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 56, 56, 128)  512        ['add_17[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_65 (BatchN  (None, 28, 28, 32)  128         ['conv2d_69[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 56, 56, 128)  0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " activation_66 (Activation)     (None, 28, 28, 32)   0           ['batch_normalization_65[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 56, 56, 32)   4128        ['activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)             (None, 28, 28, 128)  4224        ['activation_66[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 56, 56, 32)  128         ['conv2d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_24 (Add)                   (None, 28, 28, 128)  0           ['add_23[0][0]',                 \n",
      "                                                                  'conv2d_70[0][0]']              \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 56, 56, 32)   0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " up_sampling2d_4 (UpSampling2D)  (None, 56, 56, 128)  0          ['add_24[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 56, 56, 32)   9248        ['activation_50[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)             (None, 56, 56, 128)  16512       ['up_sampling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 56, 56, 32)  128         ['conv2d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)             (None, 56, 56, 128)  16512       ['conv2d_71[0][0]']              \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 56, 56, 32)   0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " activation_67 (Activation)     (None, 56, 56, 128)  0           ['conv2d_72[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 56, 56, 128)  4224        ['activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)              (None, 56, 56, 128)  0           ['activation_67[0][0]']          \n",
      "                                                                                                  \n",
      " add_18 (Add)                   (None, 56, 56, 128)  0           ['add_17[0][0]',                 \n",
      "                                                                  'conv2d_55[0][0]']              \n",
      "                                                                                                  \n",
      " multiply_1 (Multiply)          (None, 56, 56, 128)  0           ['lambda_1[0][0]',               \n",
      "                                                                  'add_18[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_66 (BatchN  (None, 56, 56, 128)  512        ['multiply_1[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_68 (Activation)     (None, 56, 56, 128)  0           ['batch_normalization_66[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)             (None, 56, 56, 32)   4128        ['activation_68[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_67 (BatchN  (None, 56, 56, 32)  128         ['conv2d_73[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_69 (Activation)     (None, 56, 56, 32)   0           ['batch_normalization_67[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)             (None, 56, 56, 32)   9248        ['activation_69[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_68 (BatchN  (None, 56, 56, 32)  128         ['conv2d_74[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_70 (Activation)     (None, 56, 56, 32)   0           ['batch_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (None, 56, 56, 128)  4224        ['activation_70[0][0]']          \n",
      "                                                                                                  \n",
      " add_25 (Add)                   (None, 56, 56, 128)  0           ['multiply_1[0][0]',             \n",
      "                                                                  'conv2d_75[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_69 (BatchN  (None, 56, 56, 128)  512        ['add_25[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_71 (Activation)     (None, 56, 56, 128)  0           ['batch_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)             (None, 56, 56, 64)   8256        ['activation_71[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_70 (BatchN  (None, 56, 56, 64)  256         ['conv2d_76[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_72 (Activation)     (None, 56, 56, 64)   0           ['batch_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)             (None, 56, 56, 64)   36928       ['activation_72[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_71 (BatchN  (None, 56, 56, 64)  256         ['conv2d_77[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_73 (Activation)     (None, 56, 56, 64)   0           ['batch_normalization_71[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)             (None, 56, 56, 256)  33024       ['add_25[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)             (None, 56, 56, 256)  16640       ['activation_73[0][0]']          \n",
      "                                                                                                  \n",
      " add_26 (Add)                   (None, 56, 56, 256)  0           ['conv2d_79[0][0]',              \n",
      "                                                                  'conv2d_78[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, 56, 56, 256)  1024       ['add_26[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_74 (Activation)     (None, 56, 56, 256)  0           ['batch_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)             (None, 56, 56, 64)   16448       ['activation_74[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, 56, 56, 64)  256         ['conv2d_80[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_75 (Activation)     (None, 56, 56, 64)   0           ['batch_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)             (None, 56, 56, 64)   36928       ['activation_75[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, 56, 56, 64)  256         ['conv2d_81[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_76 (Activation)     (None, 56, 56, 64)   0           ['batch_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)             (None, 56, 56, 256)  16640       ['activation_76[0][0]']          \n",
      "                                                                                                  \n",
      " add_27 (Add)                   (None, 56, 56, 256)  0           ['add_26[0][0]',                 \n",
      "                                                                  'conv2d_82[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPooling2D)  (None, 28, 28, 256)  0          ['add_27[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_81 (BatchN  (None, 28, 28, 256)  1024       ['max_pooling2d_6[0][0]']        \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_83 (Activation)     (None, 28, 28, 256)  0           ['batch_normalization_81[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)             (None, 28, 28, 64)   16448       ['activation_83[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_82 (BatchN  (None, 28, 28, 64)  256         ['conv2d_89[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_84 (Activation)     (None, 28, 28, 64)   0           ['batch_normalization_82[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)             (None, 28, 28, 64)   36928       ['activation_84[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, 56, 56, 256)  1024       ['add_27[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_83 (BatchN  (None, 28, 28, 64)  256         ['conv2d_90[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_77 (Activation)     (None, 56, 56, 256)  0           ['batch_normalization_75[0][0]'] \n",
      "                                                                                                  \n",
      " activation_85 (Activation)     (None, 28, 28, 64)   0           ['batch_normalization_83[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)             (None, 56, 56, 64)   16448       ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)             (None, 28, 28, 256)  16640       ['activation_85[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, 56, 56, 64)  256         ['conv2d_83[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_30 (Add)                   (None, 28, 28, 256)  0           ['max_pooling2d_6[0][0]',        \n",
      "                                                                  'conv2d_91[0][0]']              \n",
      "                                                                                                  \n",
      " activation_78 (Activation)     (None, 56, 56, 64)   0           ['batch_normalization_76[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_84 (BatchN  (None, 28, 28, 256)  1024       ['add_30[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)             (None, 56, 56, 64)   36928       ['activation_78[0][0]']          \n",
      "                                                                                                  \n",
      " activation_86 (Activation)     (None, 28, 28, 256)  0           ['batch_normalization_84[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, 56, 56, 64)  256         ['conv2d_84[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)             (None, 28, 28, 64)   16448       ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " activation_79 (Activation)     (None, 56, 56, 64)   0           ['batch_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_85 (BatchN  (None, 28, 28, 64)  256         ['conv2d_92[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)             (None, 56, 56, 256)  16640       ['activation_79[0][0]']          \n",
      "                                                                                                  \n",
      " activation_87 (Activation)     (None, 28, 28, 64)   0           ['batch_normalization_85[0][0]'] \n",
      "                                                                                                  \n",
      " add_28 (Add)                   (None, 56, 56, 256)  0           ['add_27[0][0]',                 \n",
      "                                                                  'conv2d_85[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_93 (Conv2D)             (None, 28, 28, 64)   36928       ['activation_87[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_78 (BatchN  (None, 56, 56, 256)  1024       ['add_28[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_86 (BatchN  (None, 28, 28, 64)  256         ['conv2d_93[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_80 (Activation)     (None, 56, 56, 256)  0           ['batch_normalization_78[0][0]'] \n",
      "                                                                                                  \n",
      " activation_88 (Activation)     (None, 28, 28, 64)   0           ['batch_normalization_86[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)             (None, 56, 56, 64)   16448       ['activation_80[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_94 (Conv2D)             (None, 28, 28, 256)  16640       ['activation_88[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_79 (BatchN  (None, 56, 56, 64)  256         ['conv2d_86[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_31 (Add)                   (None, 28, 28, 256)  0           ['add_30[0][0]',                 \n",
      "                                                                  'conv2d_94[0][0]']              \n",
      "                                                                                                  \n",
      " activation_81 (Activation)     (None, 56, 56, 64)   0           ['batch_normalization_79[0][0]'] \n",
      "                                                                                                  \n",
      " up_sampling2d_5 (UpSampling2D)  (None, 56, 56, 256)  0          ['add_31[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)             (None, 56, 56, 64)   36928       ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_95 (Conv2D)             (None, 56, 56, 256)  65792       ['up_sampling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_80 (BatchN  (None, 56, 56, 64)  256         ['conv2d_87[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_96 (Conv2D)             (None, 56, 56, 256)  65792       ['conv2d_95[0][0]']              \n",
      "                                                                                                  \n",
      " activation_82 (Activation)     (None, 56, 56, 64)   0           ['batch_normalization_80[0][0]'] \n",
      "                                                                                                  \n",
      " activation_89 (Activation)     (None, 56, 56, 256)  0           ['conv2d_96[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)             (None, 56, 56, 256)  16640       ['activation_82[0][0]']          \n",
      "                                                                                                  \n",
      " lambda_2 (Lambda)              (None, 56, 56, 256)  0           ['activation_89[0][0]']          \n",
      "                                                                                                  \n",
      " add_29 (Add)                   (None, 56, 56, 256)  0           ['add_28[0][0]',                 \n",
      "                                                                  'conv2d_88[0][0]']              \n",
      "                                                                                                  \n",
      " multiply_2 (Multiply)          (None, 56, 56, 256)  0           ['lambda_2[0][0]',               \n",
      "                                                                  'add_29[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_87 (BatchN  (None, 56, 56, 256)  1024       ['multiply_2[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_90 (Activation)     (None, 56, 56, 256)  0           ['batch_normalization_87[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_97 (Conv2D)             (None, 56, 56, 64)   16448       ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_88 (BatchN  (None, 56, 56, 64)  256         ['conv2d_97[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_91 (Activation)     (None, 56, 56, 64)   0           ['batch_normalization_88[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_98 (Conv2D)             (None, 56, 56, 64)   36928       ['activation_91[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_89 (BatchN  (None, 56, 56, 64)  256         ['conv2d_98[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_92 (Activation)     (None, 56, 56, 64)   0           ['batch_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_99 (Conv2D)             (None, 56, 56, 256)  16640       ['activation_92[0][0]']          \n",
      "                                                                                                  \n",
      " add_32 (Add)                   (None, 56, 56, 256)  0           ['multiply_2[0][0]',             \n",
      "                                                                  'conv2d_99[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_90 (BatchN  (None, 56, 56, 256)  1024       ['add_32[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_93 (Activation)     (None, 56, 56, 256)  0           ['batch_normalization_90[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_100 (Conv2D)            (None, 56, 56, 128)  32896       ['activation_93[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_91 (BatchN  (None, 56, 56, 128)  512        ['conv2d_100[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_94 (Activation)     (None, 56, 56, 128)  0           ['batch_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_101 (Conv2D)            (None, 56, 56, 128)  147584      ['activation_94[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_92 (BatchN  (None, 56, 56, 128)  512        ['conv2d_101[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_95 (Activation)     (None, 56, 56, 128)  0           ['batch_normalization_92[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_103 (Conv2D)            (None, 56, 56, 512)  131584      ['add_32[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_102 (Conv2D)            (None, 56, 56, 512)  66048       ['activation_95[0][0]']          \n",
      "                                                                                                  \n",
      " add_33 (Add)                   (None, 56, 56, 512)  0           ['conv2d_103[0][0]',             \n",
      "                                                                  'conv2d_102[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_93 (BatchN  (None, 56, 56, 512)  2048       ['add_33[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_96 (Activation)     (None, 56, 56, 512)  0           ['batch_normalization_93[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_104 (Conv2D)            (None, 56, 56, 128)  65664       ['activation_96[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_94 (BatchN  (None, 56, 56, 128)  512        ['conv2d_104[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_97 (Activation)     (None, 56, 56, 128)  0           ['batch_normalization_94[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_105 (Conv2D)            (None, 56, 56, 128)  147584      ['activation_97[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_95 (BatchN  (None, 56, 56, 128)  512        ['conv2d_105[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_98 (Activation)     (None, 56, 56, 128)  0           ['batch_normalization_95[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_106 (Conv2D)            (None, 56, 56, 512)  66048       ['activation_98[0][0]']          \n",
      "                                                                                                  \n",
      " add_34 (Add)                   (None, 56, 56, 512)  0           ['add_33[0][0]',                 \n",
      "                                                                  'conv2d_106[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_96 (BatchN  (None, 56, 56, 512)  2048       ['add_34[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_99 (Activation)     (None, 56, 56, 512)  0           ['batch_normalization_96[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_107 (Conv2D)            (None, 56, 56, 128)  65664       ['activation_99[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_97 (BatchN  (None, 56, 56, 128)  512        ['conv2d_107[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_100 (Activation)    (None, 56, 56, 128)  0           ['batch_normalization_97[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_108 (Conv2D)            (None, 56, 56, 128)  147584      ['activation_100[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_98 (BatchN  (None, 56, 56, 128)  512        ['conv2d_108[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_101 (Activation)    (None, 56, 56, 128)  0           ['batch_normalization_98[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_109 (Conv2D)            (None, 56, 56, 512)  66048       ['activation_101[0][0]']         \n",
      "                                                                                                  \n",
      " add_35 (Add)                   (None, 56, 56, 512)  0           ['add_34[0][0]',                 \n",
      "                                                                  'conv2d_109[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_99 (BatchN  (None, 56, 56, 512)  2048       ['add_35[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_102 (Activation)    (None, 56, 56, 512)  0           ['batch_normalization_99[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_110 (Conv2D)            (None, 56, 56, 128)  65664       ['activation_102[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_100 (Batch  (None, 56, 56, 128)  512        ['conv2d_110[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_103 (Activation)    (None, 56, 56, 128)  0           ['batch_normalization_100[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_111 (Conv2D)            (None, 56, 56, 128)  147584      ['activation_103[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_101 (Batch  (None, 56, 56, 128)  512        ['conv2d_111[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_104 (Activation)    (None, 56, 56, 128)  0           ['batch_normalization_101[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_112 (Conv2D)            (None, 56, 56, 512)  66048       ['activation_104[0][0]']         \n",
      "                                                                                                  \n",
      " add_36 (Add)                   (None, 56, 56, 512)  0           ['add_35[0][0]',                 \n",
      "                                                                  'conv2d_112[0][0]']             \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 50, 50, 512)  0          ['add_36[0][0]']                 \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 1280000)      0           ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 3)            3840003     ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 6,024,099\n",
      "Trainable params: 6,007,203\n",
      "Non-trainable params: 16,896\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ioFyOz9_c_Y"
   },
   "source": [
    "## test evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vVi9JsQYNRt2",
    "outputId": "5ff23aa2-eab0-451c-afc0-f597cb6cb985"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "915/915 [==============================] - 180s 195ms/step - loss: 0.2763 - accuracy: 0.9104\n",
      "Loss:  0.27628761529922485\n",
      "Accuracy:  91.03825092315674\n"
     ]
    }
   ],
   "source": [
    "# evaluation with last epoch weights\n",
    "loss, accuracy = model3.evaluate(test_dataset)\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OKfABf7k-7hJ",
    "outputId": "dcd056d3-1723-4e01-8cdd-4a5a80747d31"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f06a8134520>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the weights with the best accuracy of validation dataset\n",
    "model3.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_EE9N6X9_ZQV",
    "outputId": "1d1c8300-2534-40e9-8597-f9e952ec9141"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "915/915 [==============================] - 20s 21ms/step - loss: 0.2725 - accuracy: 0.9148\n",
      "Loss:  0.27248623967170715\n",
      "Accuracy:  0.9147540926933289\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model3.evaluate(test_dataset)\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z2DEoxIC_l-p",
    "outputId": "09aa88b9-e490-42c6-c546-d4984fc6fc71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "915/915 [==============================] - 20s 20ms/step\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "  test_values = model3.predict(test_dataset, steps=test_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "znvwCsjT_ptD"
   },
   "outputs": [],
   "source": [
    "#save the prediction of the model on the test dataset to use in ensemble model\n",
    "np.save(\"test_p_atten\", test_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F7UEG33mAPeW"
   },
   "source": [
    "### precision, recall, fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ajWPdzno_qff"
   },
   "outputs": [],
   "source": [
    "# preparing test result\n",
    "\n",
    "test_value_max = np.argmax(test_values,axis=1)\n",
    "test_value_max_oh = convert_to_one_hot(test_value_max,3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aOmbjA1e_3mt",
    "outputId": "2c738abe-bb44-430d-8275-9d876972a857"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 91.48%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.87      0.88      0.88       280\n",
      "       Covid       0.91      0.97      0.94       320\n",
      "   Pneumonia       0.96      0.89      0.93       315\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       915\n",
      "   macro avg       0.91      0.91      0.91       915\n",
      "weighted avg       0.92      0.91      0.91       915\n",
      " samples avg       0.91      0.91      0.91       915\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_true_oh, test_value_max_oh)\n",
    "\n",
    "print('Accuracy = {:.2f}%'.format(accuracy*100))\n",
    "print(classification_report(y_true_oh, test_value_max_oh,target_names=['Normal','Covid','Pneumonia']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0e64lTA6Lel5"
   },
   "source": [
    "###confusion matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "TMvVEbp2BE3P",
    "outputId": "20958003-7ccc-4510-9ac5-ebc6301c0eea"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 700x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cf_matrix = confusion_matrix(y_true,test_value_max)\n",
    "\n",
    "plt.figure(figsize = (7,5))\n",
    "plt.title('Attention_Resnet')\n",
    "x_axis_labels = ['Normal','Covid','Pneumonia']\n",
    "sns.heatmap(cf_matrix, annot=True,  fmt='g', cmap=\"Greens\", xticklabels=x_axis_labels, yticklabels=x_axis_labels)\n",
    "plt.xlabel('Prediction class', color = 'r')\n",
    "plt.ylabel(ylabel='True Class', color=\"r\")\n",
    "plt.savefig('h_atten.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MvZPb7BwU--J"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "w67iXX3xAtBu"
   ],
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
